{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee0caa10-a4e1-4056-b055-16e949a27792",
   "metadata": {},
   "source": [
    "# üß™ Lab 2: Document Preprocessing, Indexing, and Relevance Feedback\n",
    "\n",
    "## üìö Modules Covered\n",
    "- Module 3: Document Preprocessing, Indexing & Searching  \n",
    "- Module 4: Evaluation of IR Systems  \n",
    "- Module 5: Relevance Feedback and Query Expansion  \n",
    "\n",
    "## üîß Objective\n",
    "Implement and evaluate core IR techniques including tokenization, normalization, inverted indexing, relevance feedback, and query expansion. Build a mini IR pipeline and test its performance using precision, recall, and feedback mechanisms.\n",
    "\n",
    "## <font color='red'>Submission: Submit both .ipynb file and .ipynb converted to PDF</font>\n",
    "## <font color='blue'>Submissions with following cases will get a zero</font>\n",
    "* ## <font color='red'>Code or commented text truncated from the pdf version of the notebook</font>\n",
    "* ### <font color='blue'>Any compilation error in the notebook</font>\n",
    "* ### <font color='blue'>Missing output for any of the programming cells. There should be an output for every code cell</font>\n",
    "  \n",
    "## ‚úÖ Submission Checklist\n",
    "* Preprocessing code and inverted index output\n",
    "* Evaluation metrics for at least 3 queries\n",
    "* Expanded queries and feedback results\n",
    "* Answers to reflection questions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f15312-4c0d-4c6a-9991-fef18117c234",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Part A: Document Preprocessing and Indexing\n",
    "### Task 1: Tokenization and Normalization\n",
    "\n",
    "- Load a small corpus of 5‚Äì10 sample documents (e.g., news articles or Wikipedia snippets).\n",
    "- Apply tokenization using NLTK or spaCy.\n",
    "- Normalize tokens:\n",
    "  - Lowercasing  \n",
    "  - Removing punctuation  \n",
    "  - Handling Unicode and spelling variants  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2edb57d2-bade-4f87-b6c2-411c34931dfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Python (programming language)': 'Python is a high-level, general-purpose programming language. Its design philosophy emphasizes code readability with the use of significant indentation. Python is dynamically type-checked and garbage-collected. It supports multiple programming paradigms, including structured (particularly procedural), object-oriented and functional programming.\\nGuido van Rossum began working on Python in the late 1980s as a successor to the ABC programming language. Python 3.0, released in 2008, was a major revision and not completely backward-compatible with earlier versions. Beginning with Python 3.5, capabilities and keywords for typing were added to the language, allowing optional static typing. Currently only versions in the 3.x series are supported. \\nPython has gained widespread use in the machine learning community. It is widely taught as an introductory programming language. Since 2003, Python has consistently ranked in the top ten of the most popular programming languages in the TIOBE Programming Community Index, which ranks based on searches in 24 platforms.\\n\\n',\n",
       " 'Badminton': 'Badminton is a racquet sport played using racquets to hit a shuttlecock across a net. Although it may be played with larger teams, the most common forms of the game are \"singles\" (with one player per side) and \"doubles\" (with two players per side). Badminton is often played as a casual outdoor activity in a yard or on a beach; professional games are played on a rectangular indoor court. Points are scored by striking the shuttlecock with the racquet and landing it within the other team\\'s half of the court, within the set boundaries.\\nEach side may only strike the shuttlecock once before it passes over the net. Play ends once the shuttlecock has struck the floor or ground, or if a fault has been called by the umpire, service judge, or (in their absence) the opposing side.\\nThe shuttlecock is a feathered or (in informal matches) plastic projectile that flies differently from the balls used in many other sports. In particular, the feathers create much higher drag, causing the shuttlecock to decelerate more rapidly. Shuttlecocks also have a high top speed compared to the balls in other racquet sports, making badminton the fastest racquet sport in the world. The flight of the shuttlecock gives the sport its distinctive nature, and in certain languages the sport is named by reference to this feature (e.g., German Federball, literally feather-ball).\\nThe game developed in British India from the earlier game of battledore and shuttlecock. European play came to be dominated by Denmark but the game has become very popular in Asia. In 1992, badminton debuted as a Summer Olympic sport with four events: men\\'s singles, women\\'s singles, men\\'s doubles, and women\\'s doubles; mixed doubles was added four years later. At high levels of play, the sport demands excellent fitness: players require aerobic stamina, agility, strength, speed, and precision. It is also a technical sport, requiring good motor coordination and the development of sophisticated racquet movements involving much greater flexibility in the wrist than some other racquet sports.',\n",
       " 'Soccer': \"Association football, more commonly known as football or soccer, is a team sport played between two teams of 11 players who almost exclusively use their feet to propel a ball around a rectangular field called a pitch. \\nThe objective of the game is to score more goals than the opposing team by moving the ball beyond the goal line into a rectangular-framed goal defended by the opponent. Traditionally, the game has been played over two 45-minute halves, for a total match time of 90 minutes. With an estimated 250 million players active in over 200 countries and territories, it is the world's most popular sport.\\nAssociation football is played in accordance with the Laws of the Game, a set of rules that has been in effect since 1863 and maintained by the IFAB since 1886. The game is played with a football that is 68‚Äì70 cm (27‚Äì28 in) in circumference. The two teams compete to score goals by getting the ball into the other team's goal (between the posts, under the bar, and fully across the goal line). When the ball is in play, the players mainly use their feet, but may also use any other part of their body, except for their hands or arms, to control, strike, or pass the ball; the head, chest, and thighs are commonly used. Only the goalkeepers may use their hands and arms, but only within their own penalty area. The team that has scored more goals at the end of the game is the winner. Depending on the format of the competition, an equal number of goals scored may result in a draw being declared with 1 point awarded to each team, or the game may go into extra time or a penalty shoot-out.\\nInternationally, association football is governed by FIFA. Under FIFA, there are six continental confederations: AFC, CAF, CONCACAF, CONMEBOL, OFC, and UEFA. National associations (e.g. the FA in England, U.S. Soccer in the United States, etc.) are responsible for managing the game in their own countries both professionally and at an amateur level, and coordinating competitions in accordance with the Laws of the Game. The most prestigious senior international competition is the FIFA World Cup. The men's World Cup is the most-viewed sporting event in the world, surpassing the Olympic Games. The most prestigious competition in European club football is the UEFA Champions League, which attracts an extensive television audience worldwide. The final of the men's Champions League is the most-watched annual sporting event in the world.\",\n",
       " 'Computer Science': 'Computer science is the study of computation, information, and automation. Included broadly in the sciences, computer science spans theoretical disciplines (such as algorithms, theory of computation, and information theory) to applied disciplines (including the design and implementation of hardware and software). An expert in the field is known as a computer scientist. \\nAlgorithms and data structures are central to computer science.\\nThe theory of computation concerns abstract models of computation and general classes of problems that can be solved using them. The fields of cryptography and computer security involve studying the means for secure communication and preventing security vulnerabilities. Computer graphics and computational geometry address the generation of images. Programming language theory considers different ways to describe computational processes, and database theory concerns the management of repositories of data. Human‚Äìcomputer interaction investigates the interfaces through which humans and computers interact, and software engineering focuses on the design and principles behind developing software. Areas such as operating systems, networks and embedded systems investigate the principles and design behind complex systems. Computer architecture describes the construction of computer components and computer-operated equipment. Artificial intelligence and machine learning aim to synthesize goal-orientated processes such as problem-solving, decision-making, environmental adaptation, planning and learning found in humans and animals. Within artificial intelligence, computer vision aims to understand and process image and video data, while natural language processing aims to understand and process textual and linguistic data.\\nThe fundamental concern of computer science is determining what can and cannot be automated. The Turing Award is generally recognized as the highest distinction in computer science.\\n\\n',\n",
       " 'Data science': 'Data science is an interdisciplinary academic field that uses statistics, scientific computing, scientific methods, processing, scientific visualization, algorithms and systems to extract or extrapolate knowledge from potentially noisy, structured, or unstructured data. \\nData science also integrates domain knowledge from the underlying application domain (e.g., natural sciences, information technology, and medicine). Data science is multifaceted and can be described as a science, a research paradigm, a research method, a discipline, a workflow, and a profession.\\nData science is \"a concept to unify statistics, data analysis, informatics, and their related methods\" to \"understand and analyze actual phenomena\" with data. It uses techniques and theories drawn from many fields within the context of mathematics, statistics, computer science, information science, and domain knowledge. However, data science is different from computer science and information science. Turing Award winner Jim Gray imagined data science as a \"fourth paradigm\" of science (empirical, theoretical, computational, and now data-driven) and asserted that \"everything about science is changing because of the impact of information technology\" and the data deluge.\\nA data scientist is a professional who creates programming code and combines it with statistical knowledge to summarize data.\\n\\n'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#code/program Task 1\n",
    "\n",
    "# Using wikipedia articles\n",
    "import wikipedia\n",
    "\n",
    "titles = [\"Python (programming language)\", \"Badminton\", \"Soccer\", \"Computer Science\", \"Data science\"]\n",
    "documents = {}\n",
    "for title in titles:\n",
    "    page = wikipedia.page(title)\n",
    "    documents[title] = page.summary\n",
    "\n",
    "# Made documents a dictionary where key is title and value is the summary\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2cddd42-104a-410a-9508-c7b88beed4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing Text using NLTK\n",
    "import nltk\n",
    "tokenized_documents = {}\n",
    "for title, summary in documents.items():\n",
    "    tokenized_documents[title] = nltk.word_tokenize(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e338ed91-5209-4d60-9433-120cd005da77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Badminton', 'is', 'a', 'racquet', 'sport', 'played', 'using', 'racquets', 'to', 'hit', 'a', 'shuttlecock', 'across', 'a', 'net', '.', 'Although', 'it', 'may', 'be', 'played', 'with', 'larger', 'teams', ',', 'the', 'most', 'common', 'forms', 'of', 'the', 'game', 'are', '``', 'singles', \"''\", '(', 'with', 'one', 'player', 'per', 'side', ')', 'and', '``', 'doubles', \"''\", '(', 'with', 'two', 'players', 'per', 'side', ')', '.', 'Badminton', 'is', 'often', 'played', 'as', 'a', 'casual', 'outdoor', 'activity', 'in', 'a', 'yard', 'or', 'on', 'a', 'beach', ';', 'professional', 'games', 'are', 'played', 'on', 'a', 'rectangular', 'indoor', 'court', '.', 'Points', 'are', 'scored', 'by', 'striking', 'the', 'shuttlecock', 'with', 'the', 'racquet', 'and', 'landing', 'it', 'within', 'the', 'other', 'team', \"'s\", 'half', 'of', 'the', 'court', ',', 'within', 'the', 'set', 'boundaries', '.', 'Each', 'side', 'may', 'only', 'strike', 'the', 'shuttlecock', 'once', 'before', 'it', 'passes', 'over', 'the', 'net', '.', 'Play', 'ends', 'once', 'the', 'shuttlecock', 'has', 'struck', 'the', 'floor', 'or', 'ground', ',', 'or', 'if', 'a', 'fault', 'has', 'been', 'called', 'by', 'the', 'umpire', ',', 'service', 'judge', ',', 'or', '(', 'in', 'their', 'absence', ')', 'the', 'opposing', 'side', '.', 'The', 'shuttlecock', 'is', 'a', 'feathered', 'or', '(', 'in', 'informal', 'matches', ')', 'plastic', 'projectile', 'that', 'flies', 'differently', 'from', 'the', 'balls', 'used', 'in', 'many', 'other', 'sports', '.', 'In', 'particular', ',', 'the', 'feathers', 'create', 'much', 'higher', 'drag', ',', 'causing', 'the', 'shuttlecock', 'to', 'decelerate', 'more', 'rapidly', '.', 'Shuttlecocks', 'also', 'have', 'a', 'high', 'top', 'speed', 'compared', 'to', 'the', 'balls', 'in', 'other', 'racquet', 'sports', ',', 'making', 'badminton', 'the', 'fastest', 'racquet', 'sport', 'in', 'the', 'world', '.', 'The', 'flight', 'of', 'the', 'shuttlecock', 'gives', 'the', 'sport', 'its', 'distinctive', 'nature', ',', 'and', 'in', 'certain', 'languages', 'the', 'sport', 'is', 'named', 'by', 'reference', 'to', 'this', 'feature', '(', 'e.g.', ',', 'German', 'Federball', ',', 'literally', 'feather-ball', ')', '.', 'The', 'game', 'developed', 'in', 'British', 'India', 'from', 'the', 'earlier', 'game', 'of', 'battledore', 'and', 'shuttlecock', '.', 'European', 'play', 'came', 'to', 'be', 'dominated', 'by', 'Denmark', 'but', 'the', 'game', 'has', 'become', 'very', 'popular', 'in', 'Asia', '.', 'In', '1992', ',', 'badminton', 'debuted', 'as', 'a', 'Summer', 'Olympic', 'sport', 'with', 'four', 'events', ':', 'men', \"'s\", 'singles', ',', 'women', \"'s\", 'singles', ',', 'men', \"'s\", 'doubles', ',', 'and', 'women', \"'s\", 'doubles', ';', 'mixed', 'doubles', 'was', 'added', 'four', 'years', 'later', '.', 'At', 'high', 'levels', 'of', 'play', ',', 'the', 'sport', 'demands', 'excellent', 'fitness', ':', 'players', 'require', 'aerobic', 'stamina', ',', 'agility', ',', 'strength', ',', 'speed', ',', 'and', 'precision', '.', 'It', 'is', 'also', 'a', 'technical', 'sport', ',', 'requiring', 'good', 'motor', 'coordination', 'and', 'the', 'development', 'of', 'sophisticated', 'racquet', 'movements', 'involving', 'much', 'greater', 'flexibility', 'in', 'the', 'wrist', 'than', 'some', 'other', 'racquet', 'sports', '.']\n"
     ]
    }
   ],
   "source": [
    "# This is a dictionary of lists, where the key is the title,\n",
    "# and the value is a list of tokenized terms per document\n",
    "print(tokenized_documents[\"Badminton\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f2065ad-1a31-4d60-bbd1-c454c60a0d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['badminton', 'is', 'a', 'racquet', 'sport', 'played', 'using', 'racquets', 'to', 'hit', 'a', 'shuttlecock', 'across', 'a', 'net', '.', 'although', 'it', 'may', 'be', 'played', 'with', 'larger', 'teams', ',', 'the', 'most', 'common', 'forms', 'of', 'the', 'game', 'are', '``', 'singles', \"''\", '(', 'with', 'one', 'player', 'per', 'side', ')', 'and', '``', 'doubles', \"''\", '(', 'with', 'two', 'players', 'per', 'side', ')', '.', 'badminton', 'is', 'often', 'played', 'as', 'a', 'casual', 'outdoor', 'activity', 'in', 'a', 'yard', 'or', 'on', 'a', 'beach', ';', 'professional', 'games', 'are', 'played', 'on', 'a', 'rectangular', 'indoor', 'court', '.', 'points', 'are', 'scored', 'by', 'striking', 'the', 'shuttlecock', 'with', 'the', 'racquet', 'and', 'landing', 'it', 'within', 'the', 'other', 'team', \"'s\", 'half', 'of', 'the', 'court', ',', 'within', 'the', 'set', 'boundaries', '.', 'each', 'side', 'may', 'only', 'strike', 'the', 'shuttlecock', 'once', 'before', 'it', 'passes', 'over', 'the', 'net', '.', 'play', 'ends', 'once', 'the', 'shuttlecock', 'has', 'struck', 'the', 'floor', 'or', 'ground', ',', 'or', 'if', 'a', 'fault', 'has', 'been', 'called', 'by', 'the', 'umpire', ',', 'service', 'judge', ',', 'or', '(', 'in', 'their', 'absence', ')', 'the', 'opposing', 'side', '.', 'the', 'shuttlecock', 'is', 'a', 'feathered', 'or', '(', 'in', 'informal', 'matches', ')', 'plastic', 'projectile', 'that', 'flies', 'differently', 'from', 'the', 'balls', 'used', 'in', 'many', 'other', 'sports', '.', 'in', 'particular', ',', 'the', 'feathers', 'create', 'much', 'higher', 'drag', ',', 'causing', 'the', 'shuttlecock', 'to', 'decelerate', 'more', 'rapidly', '.', 'shuttlecocks', 'also', 'have', 'a', 'high', 'top', 'speed', 'compared', 'to', 'the', 'balls', 'in', 'other', 'racquet', 'sports', ',', 'making', 'badminton', 'the', 'fastest', 'racquet', 'sport', 'in', 'the', 'world', '.', 'the', 'flight', 'of', 'the', 'shuttlecock', 'gives', 'the', 'sport', 'its', 'distinctive', 'nature', ',', 'and', 'in', 'certain', 'languages', 'the', 'sport', 'is', 'named', 'by', 'reference', 'to', 'this', 'feature', '(', 'e.g.', ',', 'german', 'federball', ',', 'literally', 'feather-ball', ')', '.', 'the', 'game', 'developed', 'in', 'british', 'india', 'from', 'the', 'earlier', 'game', 'of', 'battledore', 'and', 'shuttlecock', '.', 'european', 'play', 'came', 'to', 'be', 'dominated', 'by', 'denmark', 'but', 'the', 'game', 'has', 'become', 'very', 'popular', 'in', 'asia', '.', 'in', '1992', ',', 'badminton', 'debuted', 'as', 'a', 'summer', 'olympic', 'sport', 'with', 'four', 'events', ':', 'men', \"'s\", 'singles', ',', 'women', \"'s\", 'singles', ',', 'men', \"'s\", 'doubles', ',', 'and', 'women', \"'s\", 'doubles', ';', 'mixed', 'doubles', 'was', 'added', 'four', 'years', 'later', '.', 'at', 'high', 'levels', 'of', 'play', ',', 'the', 'sport', 'demands', 'excellent', 'fitness', ':', 'players', 'require', 'aerobic', 'stamina', ',', 'agility', ',', 'strength', ',', 'speed', ',', 'and', 'precision', '.', 'it', 'is', 'also', 'a', 'technical', 'sport', ',', 'requiring', 'good', 'motor', 'coordination', 'and', 'the', 'development', 'of', 'sophisticated', 'racquet', 'movements', 'involving', 'much', 'greater', 'flexibility', 'in', 'the', 'wrist', 'than', 'some', 'other', 'racquet', 'sports', '.']\n"
     ]
    }
   ],
   "source": [
    "# Normalizing tokens (FIRST, LOWERCASING)\n",
    "lowercased_tokenized_documents = {}\n",
    "for title, tokenized_doc in tokenized_documents.items():\n",
    "    lowercased_tokenized_documents[title.lower()] = [token.lower() for token in tokenized_doc]\n",
    "\n",
    "# Using badminton document as the reference document to show in this report\n",
    "print(lowercased_tokenized_documents[\"badminton\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d85fec0-8530-4454-b6fe-505c3980c75f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['badminton', 'is', 'a', 'racquet', 'sport', 'played', 'using', 'racquets', 'to', 'hit', 'a', 'shuttlecock', 'across', 'a', 'net', 'although', 'it', 'may', 'be', 'played', 'with', 'larger', 'teams', 'the', 'most', 'common', 'forms', 'of', 'the', 'game', 'are', 'singles', 'with', 'one', 'player', 'per', 'side', 'and', 'doubles', 'with', 'two', 'players', 'per', 'side', 'badminton', 'is', 'often', 'played', 'as', 'a', 'casual', 'outdoor', 'activity', 'in', 'a', 'yard', 'or', 'on', 'a', 'beach', 'professional', 'games', 'are', 'played', 'on', 'a', 'rectangular', 'indoor', 'court', 'points', 'are', 'scored', 'by', 'striking', 'the', 'shuttlecock', 'with', 'the', 'racquet', 'and', 'landing', 'it', 'within', 'the', 'other', 'team', 'half', 'of', 'the', 'court', 'within', 'the', 'set', 'boundaries', 'each', 'side', 'may', 'only', 'strike', 'the', 'shuttlecock', 'once', 'before', 'it', 'passes', 'over', 'the', 'net', 'play', 'ends', 'once', 'the', 'shuttlecock', 'has', 'struck', 'the', 'floor', 'or', 'ground', 'or', 'if', 'a', 'fault', 'has', 'been', 'called', 'by', 'the', 'umpire', 'service', 'judge', 'or', 'in', 'their', 'absence', 'the', 'opposing', 'side', 'the', 'shuttlecock', 'is', 'a', 'feathered', 'or', 'in', 'informal', 'matches', 'plastic', 'projectile', 'that', 'flies', 'differently', 'from', 'the', 'balls', 'used', 'in', 'many', 'other', 'sports', 'in', 'particular', 'the', 'feathers', 'create', 'much', 'higher', 'drag', 'causing', 'the', 'shuttlecock', 'to', 'decelerate', 'more', 'rapidly', 'shuttlecocks', 'also', 'have', 'a', 'high', 'top', 'speed', 'compared', 'to', 'the', 'balls', 'in', 'other', 'racquet', 'sports', 'making', 'badminton', 'the', 'fastest', 'racquet', 'sport', 'in', 'the', 'world', 'the', 'flight', 'of', 'the', 'shuttlecock', 'gives', 'the', 'sport', 'its', 'distinctive', 'nature', 'and', 'in', 'certain', 'languages', 'the', 'sport', 'is', 'named', 'by', 'reference', 'to', 'this', 'feature', 'german', 'federball', 'literally', 'the', 'game', 'developed', 'in', 'british', 'india', 'from', 'the', 'earlier', 'game', 'of', 'battledore', 'and', 'shuttlecock', 'european', 'play', 'came', 'to', 'be', 'dominated', 'by', 'denmark', 'but', 'the', 'game', 'has', 'become', 'very', 'popular', 'in', 'asia', 'in', 'badminton', 'debuted', 'as', 'a', 'summer', 'olympic', 'sport', 'with', 'four', 'events', 'men', 'singles', 'women', 'singles', 'men', 'doubles', 'and', 'women', 'doubles', 'mixed', 'doubles', 'was', 'added', 'four', 'years', 'later', 'at', 'high', 'levels', 'of', 'play', 'the', 'sport', 'demands', 'excellent', 'fitness', 'players', 'require', 'aerobic', 'stamina', 'agility', 'strength', 'speed', 'and', 'precision', 'it', 'is', 'also', 'a', 'technical', 'sport', 'requiring', 'good', 'motor', 'coordination', 'and', 'the', 'development', 'of', 'sophisticated', 'racquet', 'movements', 'involving', 'much', 'greater', 'flexibility', 'in', 'the', 'wrist', 'than', 'some', 'other', 'racquet', 'sports']\n"
     ]
    }
   ],
   "source": [
    "# REMOVING PUNCTUATION AND HANDLING UNICODE USING isascii()\n",
    "normalized_tokenized_documents = {}\n",
    "\n",
    "for title, lowercased_doc in lowercased_tokenized_documents.items():\n",
    "    normalized_tokenized_documents[title] = [\n",
    "        token for token in lowercased_doc if token.isalpha() and token.isascii()\n",
    "    ]\n",
    "\n",
    "print(normalized_tokenized_documents[\"badminton\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3387d0-6362-4aaf-bce0-d9fe1754b335",
   "metadata": {},
   "source": [
    "### Task 2: Stop Word Removal and Stemming\n",
    "\n",
    "- Remove stop words using a standard list (e.g., NLTK‚Äôs English stopwords).\n",
    "- Apply stemming (Porter or Snowball) and compare with lemmatization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21b6f595-6226-4288-a842-aa8b37817ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['badminton', 'racquet', 'sport', 'played', 'using', 'racquets', 'hit', 'shuttlecock', 'across', 'net', 'although', 'may', 'played', 'larger', 'teams', 'common', 'forms', 'game', 'singles', 'one', 'player', 'per', 'side', 'doubles', 'two', 'players', 'per', 'side', 'badminton', 'often', 'played', 'casual', 'outdoor', 'activity', 'yard', 'beach', 'professional', 'games', 'played', 'rectangular', 'indoor', 'court', 'points', 'scored', 'striking', 'shuttlecock', 'racquet', 'landing', 'within', 'team', 'half', 'court', 'within', 'set', 'boundaries', 'side', 'may', 'strike', 'shuttlecock', 'passes', 'net', 'play', 'ends', 'shuttlecock', 'struck', 'floor', 'ground', 'fault', 'called', 'umpire', 'service', 'judge', 'absence', 'opposing', 'side', 'shuttlecock', 'feathered', 'informal', 'matches', 'plastic', 'projectile', 'flies', 'differently', 'balls', 'used', 'many', 'sports', 'particular', 'feathers', 'create', 'much', 'higher', 'drag', 'causing', 'shuttlecock', 'decelerate', 'rapidly', 'shuttlecocks', 'also', 'high', 'top', 'speed', 'compared', 'balls', 'racquet', 'sports', 'making', 'badminton', 'fastest', 'racquet', 'sport', 'world', 'flight', 'shuttlecock', 'gives', 'sport', 'distinctive', 'nature', 'certain', 'languages', 'sport', 'named', 'reference', 'feature', 'german', 'federball', 'literally', 'game', 'developed', 'british', 'india', 'earlier', 'game', 'battledore', 'shuttlecock', 'european', 'play', 'came', 'dominated', 'denmark', 'game', 'become', 'popular', 'asia', 'badminton', 'debuted', 'summer', 'olympic', 'sport', 'four', 'events', 'men', 'singles', 'women', 'singles', 'men', 'doubles', 'women', 'doubles', 'mixed', 'doubles', 'added', 'four', 'years', 'later', 'high', 'levels', 'play', 'sport', 'demands', 'excellent', 'fitness', 'players', 'require', 'aerobic', 'stamina', 'agility', 'strength', 'speed', 'precision', 'also', 'technical', 'sport', 'requiring', 'good', 'motor', 'coordination', 'development', 'sophisticated', 'racquet', 'movements', 'involving', 'much', 'greater', 'flexibility', 'wrist', 'racquet', 'sports']\n"
     ]
    }
   ],
   "source": [
    "#code/program Task 2\n",
    "# Stop word removal\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')\n",
    "\n",
    "removed_stopwords_tokenized_documents = {}\n",
    "for title, normalized_doc in normalized_tokenized_documents.items():\n",
    "    removed_stopwords_tokenized_documents[title] = [\n",
    "        token for token in normalized_doc if token not in stopwords\n",
    "    ]\n",
    "\n",
    "print(removed_stopwords_tokenized_documents[\"badminton\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08facb56-63bd-4515-92cb-88ecb95f1b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['badminton', 'racquet', 'sport', 'play', 'use', 'racquet', 'hit', 'shuttlecock', 'across', 'net', 'although', 'may', 'play', 'larger', 'team', 'common', 'form', 'game', 'singl', 'one', 'player', 'per', 'side', 'doubl', 'two', 'player', 'per', 'side', 'badminton', 'often', 'play', 'casual', 'outdoor', 'activ', 'yard', 'beach', 'profession', 'game', 'play', 'rectangular', 'indoor', 'court', 'point', 'score', 'strike', 'shuttlecock', 'racquet', 'land', 'within', 'team', 'half', 'court', 'within', 'set', 'boundari', 'side', 'may', 'strike', 'shuttlecock', 'pass', 'net', 'play', 'end', 'shuttlecock', 'struck', 'floor', 'ground', 'fault', 'call', 'umpir', 'servic', 'judg', 'absenc', 'oppos', 'side', 'shuttlecock', 'feather', 'inform', 'match', 'plastic', 'projectil', 'fli', 'differ', 'ball', 'use', 'mani', 'sport', 'particular', 'feather', 'creat', 'much', 'higher', 'drag', 'caus', 'shuttlecock', 'deceler', 'rapidli', 'shuttlecock', 'also', 'high', 'top', 'speed', 'compar', 'ball', 'racquet', 'sport', 'make', 'badminton', 'fastest', 'racquet', 'sport', 'world', 'flight', 'shuttlecock', 'give', 'sport', 'distinct', 'natur', 'certain', 'languag', 'sport', 'name', 'refer', 'featur', 'german', 'federbal', 'liter', 'game', 'develop', 'british', 'india', 'earlier', 'game', 'battledor', 'shuttlecock', 'european', 'play', 'came', 'domin', 'denmark', 'game', 'becom', 'popular', 'asia', 'badminton', 'debut', 'summer', 'olymp', 'sport', 'four', 'event', 'men', 'singl', 'women', 'singl', 'men', 'doubl', 'women', 'doubl', 'mix', 'doubl', 'ad', 'four', 'year', 'later', 'high', 'level', 'play', 'sport', 'demand', 'excel', 'fit', 'player', 'requir', 'aerob', 'stamina', 'agil', 'strength', 'speed', 'precis', 'also', 'technic', 'sport', 'requir', 'good', 'motor', 'coordin', 'develop', 'sophist', 'racquet', 'movement', 'involv', 'much', 'greater', 'flexibl', 'wrist', 'racquet', 'sport']\n"
     ]
    }
   ],
   "source": [
    "# Porter Stemmer\n",
    "from nltk.stem import PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "\n",
    "porter_tokenized_documents = {}\n",
    "for title, no_stopword_doc in removed_stopwords_tokenized_documents.items():\n",
    "    porter_tokenized_documents[title] = [porter.stem(token) for token in no_stopword_doc]\n",
    "\n",
    "print(porter_tokenized_documents[\"badminton\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a0d9ba9-186f-444e-9f00-3121dc5deeb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['badminton', 'racquet', 'sport', 'played', 'using', 'racquet', 'hit', 'shuttlecock', 'across', 'net', 'although', 'may', 'played', 'larger', 'team', 'common', 'form', 'game', 'single', 'one', 'player', 'per', 'side', 'double', 'two', 'player', 'per', 'side', 'badminton', 'often', 'played', 'casual', 'outdoor', 'activity', 'yard', 'beach', 'professional', 'game', 'played', 'rectangular', 'indoor', 'court', 'point', 'scored', 'striking', 'shuttlecock', 'racquet', 'landing', 'within', 'team', 'half', 'court', 'within', 'set', 'boundary', 'side', 'may', 'strike', 'shuttlecock', 'pass', 'net', 'play', 'end', 'shuttlecock', 'struck', 'floor', 'ground', 'fault', 'called', 'umpire', 'service', 'judge', 'absence', 'opposing', 'side', 'shuttlecock', 'feathered', 'informal', 'match', 'plastic', 'projectile', 'fly', 'differently', 'ball', 'used', 'many', 'sport', 'particular', 'feather', 'create', 'much', 'higher', 'drag', 'causing', 'shuttlecock', 'decelerate', 'rapidly', 'shuttlecock', 'also', 'high', 'top', 'speed', 'compared', 'ball', 'racquet', 'sport', 'making', 'badminton', 'fastest', 'racquet', 'sport', 'world', 'flight', 'shuttlecock', 'give', 'sport', 'distinctive', 'nature', 'certain', 'language', 'sport', 'named', 'reference', 'feature', 'german', 'federball', 'literally', 'game', 'developed', 'british', 'india', 'earlier', 'game', 'battledore', 'shuttlecock', 'european', 'play', 'came', 'dominated', 'denmark', 'game', 'become', 'popular', 'asia', 'badminton', 'debuted', 'summer', 'olympic', 'sport', 'four', 'event', 'men', 'single', 'woman', 'single', 'men', 'double', 'woman', 'double', 'mixed', 'double', 'added', 'four', 'year', 'later', 'high', 'level', 'play', 'sport', 'demand', 'excellent', 'fitness', 'player', 'require', 'aerobic', 'stamen', 'agility', 'strength', 'speed', 'precision', 'also', 'technical', 'sport', 'requiring', 'good', 'motor', 'coordination', 'development', 'sophisticated', 'racquet', 'movement', 'involving', 'much', 'greater', 'flexibility', 'wrist', 'racquet', 'sport']\n"
     ]
    }
   ],
   "source": [
    "# Lemmatization\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "lemma_tokenized_documents = {}\n",
    "for title, no_stopword_doc in removed_stopwords_tokenized_documents.items():\n",
    "    lemma_tokenized_documents[title] = [lemma.lemmatize(token) for token in no_stopword_doc]\n",
    "\n",
    "print(lemma_tokenized_documents[\"badminton\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91338e0-7477-4b41-9e7a-688685d6856c",
   "metadata": {},
   "source": [
    "When comparing Lemmatization and Porter stemmer, we notice that the porter stemmer may be less accurate due some some words being stemmed incorrectly. For example, we notice in the porter stemmer dictionary, the word \"doubles\" got stemmed into \"doubl\", which clearly is not right. It was also noticeable that the lemmatization cell took slightly longer to run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171dd6c7-aee4-4572-be4b-9ac35e712fc0",
   "metadata": {},
   "source": [
    "### Task 3: Build an Inverted Index\n",
    "\n",
    "- Create a dictionary mapping each term to a list of document IDs.\n",
    "- Store term positions for phrase search support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6473cc84-9f86-4087-91b9-65d05c6a5e6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'python': {'python (programming language)': [0, 11, 28, 34, 42, 56, 69]},\n",
       " 'programming': {'python (programming language)': [1, 15, 22, 32, 66, 75, 78],\n",
       "  'computer science': [67],\n",
       "  'data science': [116]},\n",
       " 'language': {'python (programming language)': [2, 33, 47, 67, 76],\n",
       "  'badminton': [119],\n",
       "  'computer science': [68, 141]},\n",
       " 'design': {'python (programming language)': [3],\n",
       "  'computer science': [22, 91, 104]},\n",
       " 'philosophy': {'python (programming language)': [4]},\n",
       " 'emphasizes': {'python (programming language)': [5]},\n",
       " 'code': {'python (programming language)': [6], 'data science': [117]},\n",
       " 'readability': {'python (programming language)': [7]},\n",
       " 'use': {'python (programming language)': [8, 59],\n",
       "  'soccer': [14, 92, 96, 113]},\n",
       " 'significant': {'python (programming language)': [9]},\n",
       " 'indentation': {'python (programming language)': [10]},\n",
       " 'dynamically': {'python (programming language)': [12]},\n",
       " 'support': {'python (programming language)': [13]},\n",
       " 'multiple': {'python (programming language)': [14]},\n",
       " 'paradigm': {'python (programming language)': [16], 'data science': [44, 98]},\n",
       " 'including': {'python (programming language)': [17],\n",
       "  'computer science': [21]},\n",
       " 'structured': {'python (programming language)': [18], 'data science': [21]},\n",
       " 'particularly': {'python (programming language)': [19]},\n",
       " 'procedural': {'python (programming language)': [20]},\n",
       " 'functional': {'python (programming language)': [21]},\n",
       " 'guido': {'python (programming language)': [23]},\n",
       " 'van': {'python (programming language)': [24]},\n",
       " 'rossum': {'python (programming language)': [25]},\n",
       " 'began': {'python (programming language)': [26]},\n",
       " 'working': {'python (programming language)': [27]},\n",
       " 'late': {'python (programming language)': [29]},\n",
       " 'successor': {'python (programming language)': [30]},\n",
       " 'abc': {'python (programming language)': [31]},\n",
       " 'released': {'python (programming language)': [35]},\n",
       " 'major': {'python (programming language)': [36]},\n",
       " 'revision': {'python (programming language)': [37]},\n",
       " 'completely': {'python (programming language)': [38]},\n",
       " 'earlier': {'python (programming language)': [39], 'badminton': [131]},\n",
       " 'version': {'python (programming language)': [40, 53]},\n",
       " 'beginning': {'python (programming language)': [41]},\n",
       " 'capability': {'python (programming language)': [43]},\n",
       " 'keywords': {'python (programming language)': [44]},\n",
       " 'typing': {'python (programming language)': [45, 51]},\n",
       " 'added': {'python (programming language)': [46], 'badminton': [161]},\n",
       " 'allowing': {'python (programming language)': [48]},\n",
       " 'optional': {'python (programming language)': [49]},\n",
       " 'static': {'python (programming language)': [50]},\n",
       " 'currently': {'python (programming language)': [52]},\n",
       " 'series': {'python (programming language)': [54]},\n",
       " 'supported': {'python (programming language)': [55]},\n",
       " 'gained': {'python (programming language)': [57]},\n",
       " 'widespread': {'python (programming language)': [58]},\n",
       " 'machine': {'python (programming language)': [60], 'computer science': [117]},\n",
       " 'learning': {'python (programming language)': [61],\n",
       "  'computer science': [118, 125]},\n",
       " 'community': {'python (programming language)': [62, 79]},\n",
       " 'widely': {'python (programming language)': [63]},\n",
       " 'taught': {'python (programming language)': [64]},\n",
       " 'introductory': {'python (programming language)': [65]},\n",
       " 'since': {'python (programming language)': [68], 'soccer': [64, 67]},\n",
       " 'consistently': {'python (programming language)': [70]},\n",
       " 'ranked': {'python (programming language)': [71]},\n",
       " 'top': {'python (programming language)': [72], 'badminton': [100]},\n",
       " 'ten': {'python (programming language)': [73]},\n",
       " 'popular': {'python (programming language)': [74],\n",
       "  'badminton': [142],\n",
       "  'soccer': [53]},\n",
       " 'tiobe': {'python (programming language)': [77]},\n",
       " 'index': {'python (programming language)': [80]},\n",
       " 'rank': {'python (programming language)': [81]},\n",
       " 'based': {'python (programming language)': [82]},\n",
       " 'search': {'python (programming language)': [83]},\n",
       " 'platform': {'python (programming language)': [84]},\n",
       " 'badminton': {'badminton': [0, 28, 107, 144]},\n",
       " 'racquet': {'badminton': [1, 5, 46, 104, 109, 189, 196]},\n",
       " 'sport': {'badminton': [2, 86, 105, 110, 115, 120, 148, 168, 182, 197],\n",
       "  'soccer': [7, 54]},\n",
       " 'played': {'badminton': [3, 12, 30, 38], 'soccer': [8, 39, 57, 69]},\n",
       " 'using': {'badminton': [4], 'computer science': [47]},\n",
       " 'hit': {'badminton': [6]},\n",
       " 'shuttlecock': {'badminton': [7, 45, 58, 63, 75, 94, 97, 113, 134]},\n",
       " 'across': {'badminton': [8], 'soccer': [85]},\n",
       " 'net': {'badminton': [9, 60]},\n",
       " 'although': {'badminton': [10]},\n",
       " 'may': {'badminton': [11, 56], 'soccer': [94, 112, 132, 140]},\n",
       " 'larger': {'badminton': [13]},\n",
       " 'team': {'badminton': [14, 49], 'soccer': [6, 10, 28, 74, 80, 119, 138]},\n",
       " 'common': {'badminton': [15]},\n",
       " 'form': {'badminton': [16]},\n",
       " 'game': {'badminton': [17, 37, 127, 132, 140],\n",
       "  'soccer': [24, 38, 60, 68, 123, 139, 170, 179, 195]},\n",
       " 'single': {'badminton': [18, 152, 154]},\n",
       " 'one': {'badminton': [19]},\n",
       " 'player': {'badminton': [20, 25, 172], 'soccer': [11, 48, 90]},\n",
       " 'per': {'badminton': [21, 26]},\n",
       " 'side': {'badminton': [22, 27, 55, 74]},\n",
       " 'double': {'badminton': [23, 156, 158, 160]},\n",
       " 'two': {'badminton': [24], 'soccer': [9, 40, 73]},\n",
       " 'often': {'badminton': [29]},\n",
       " 'casual': {'badminton': [31]},\n",
       " 'outdoor': {'badminton': [32]},\n",
       " 'activity': {'badminton': [33]},\n",
       " 'yard': {'badminton': [34]},\n",
       " 'beach': {'badminton': [35]},\n",
       " 'professional': {'badminton': [36], 'data science': [114]},\n",
       " 'rectangular': {'badminton': [39], 'soccer': [19]},\n",
       " 'indoor': {'badminton': [40]},\n",
       " 'court': {'badminton': [41, 51]},\n",
       " 'point': {'badminton': [42], 'soccer': [136]},\n",
       " 'scored': {'badminton': [43], 'soccer': [120, 131]},\n",
       " 'striking': {'badminton': [44]},\n",
       " 'landing': {'badminton': [47]},\n",
       " 'within': {'badminton': [48, 52],\n",
       "  'soccer': [116],\n",
       "  'computer science': [129],\n",
       "  'data science': [71]},\n",
       " 'half': {'badminton': [50], 'soccer': [41]},\n",
       " 'set': {'badminton': [53], 'soccer': [61]},\n",
       " 'boundary': {'badminton': [54]},\n",
       " 'strike': {'badminton': [57], 'soccer': [103]},\n",
       " 'pass': {'badminton': [59]},\n",
       " 'play': {'badminton': [61, 136, 167], 'soccer': [89]},\n",
       " 'end': {'badminton': [62], 'soccer': [122]},\n",
       " 'struck': {'badminton': [64]},\n",
       " 'floor': {'badminton': [65]},\n",
       " 'ground': {'badminton': [66]},\n",
       " 'fault': {'badminton': [67]},\n",
       " 'called': {'badminton': [68], 'soccer': [21]},\n",
       " 'umpire': {'badminton': [69]},\n",
       " 'service': {'badminton': [70]},\n",
       " 'judge': {'badminton': [71]},\n",
       " 'absence': {'badminton': [72]},\n",
       " 'opposing': {'badminton': [73], 'soccer': [27]},\n",
       " 'feathered': {'badminton': [76]},\n",
       " 'informal': {'badminton': [77]},\n",
       " 'match': {'badminton': [78], 'soccer': [43]},\n",
       " 'plastic': {'badminton': [79]},\n",
       " 'projectile': {'badminton': [80]},\n",
       " 'fly': {'badminton': [81]},\n",
       " 'differently': {'badminton': [82]},\n",
       " 'ball': {'badminton': [83, 103], 'soccer': [17, 30, 79, 88, 105]},\n",
       " 'used': {'badminton': [84], 'soccer': [110]},\n",
       " 'many': {'badminton': [85], 'data science': [69]},\n",
       " 'particular': {'badminton': [87]},\n",
       " 'feather': {'badminton': [88]},\n",
       " 'create': {'badminton': [89]},\n",
       " 'much': {'badminton': [90, 192]},\n",
       " 'higher': {'badminton': [91]},\n",
       " 'drag': {'badminton': [92]},\n",
       " 'causing': {'badminton': [93]},\n",
       " 'decelerate': {'badminton': [95]},\n",
       " 'rapidly': {'badminton': [96]},\n",
       " 'also': {'badminton': [98, 180], 'soccer': [95], 'data science': [26]},\n",
       " 'high': {'badminton': [99, 165]},\n",
       " 'speed': {'badminton': [101, 178]},\n",
       " 'compared': {'badminton': [102]},\n",
       " 'making': {'badminton': [106]},\n",
       " 'fastest': {'badminton': [108]},\n",
       " 'world': {'badminton': [111], 'soccer': [52, 185, 188, 192, 216]},\n",
       " 'flight': {'badminton': [112]},\n",
       " 'give': {'badminton': [114]},\n",
       " 'distinctive': {'badminton': [116]},\n",
       " 'nature': {'badminton': [117]},\n",
       " 'certain': {'badminton': [118]},\n",
       " 'named': {'badminton': [121]},\n",
       " 'reference': {'badminton': [122]},\n",
       " 'feature': {'badminton': [123]},\n",
       " 'german': {'badminton': [124]},\n",
       " 'federball': {'badminton': [125]},\n",
       " 'literally': {'badminton': [126]},\n",
       " 'developed': {'badminton': [128]},\n",
       " 'british': {'badminton': [129]},\n",
       " 'india': {'badminton': [130]},\n",
       " 'battledore': {'badminton': [133]},\n",
       " 'european': {'badminton': [135], 'soccer': [198]},\n",
       " 'came': {'badminton': [137]},\n",
       " 'dominated': {'badminton': [138]},\n",
       " 'denmark': {'badminton': [139]},\n",
       " 'become': {'badminton': [141]},\n",
       " 'asia': {'badminton': [143]},\n",
       " 'debuted': {'badminton': [145]},\n",
       " 'summer': {'badminton': [146]},\n",
       " 'olympic': {'badminton': [147], 'soccer': [194]},\n",
       " 'four': {'badminton': [149, 162]},\n",
       " 'event': {'badminton': [150], 'soccer': [191, 215]},\n",
       " 'men': {'badminton': [151, 155], 'soccer': [187, 210]},\n",
       " 'woman': {'badminton': [153, 157]},\n",
       " 'mixed': {'badminton': [159]},\n",
       " 'year': {'badminton': [163]},\n",
       " 'later': {'badminton': [164]},\n",
       " 'level': {'badminton': [166], 'soccer': [174]},\n",
       " 'demand': {'badminton': [169]},\n",
       " 'excellent': {'badminton': [170]},\n",
       " 'fitness': {'badminton': [171]},\n",
       " 'require': {'badminton': [173]},\n",
       " 'aerobic': {'badminton': [174]},\n",
       " 'stamen': {'badminton': [175]},\n",
       " 'agility': {'badminton': [176]},\n",
       " 'strength': {'badminton': [177]},\n",
       " 'precision': {'badminton': [179]},\n",
       " 'technical': {'badminton': [181]},\n",
       " 'requiring': {'badminton': [183]},\n",
       " 'good': {'badminton': [184]},\n",
       " 'motor': {'badminton': [185]},\n",
       " 'coordination': {'badminton': [186]},\n",
       " 'development': {'badminton': [187]},\n",
       " 'sophisticated': {'badminton': [188]},\n",
       " 'movement': {'badminton': [190]},\n",
       " 'involving': {'badminton': [191]},\n",
       " 'greater': {'badminton': [193]},\n",
       " 'flexibility': {'badminton': [194]},\n",
       " 'wrist': {'badminton': [195]},\n",
       " 'association': {'soccer': [0, 55, 146, 161]},\n",
       " 'football': {'soccer': [1, 4, 56, 70, 147, 200]},\n",
       " 'commonly': {'soccer': [2, 109]},\n",
       " 'known': {'soccer': [3], 'computer science': [28]},\n",
       " 'soccer': {'soccer': [5, 164]},\n",
       " 'almost': {'soccer': [12]},\n",
       " 'exclusively': {'soccer': [13]},\n",
       " 'foot': {'soccer': [15, 93]},\n",
       " 'propel': {'soccer': [16]},\n",
       " 'around': {'soccer': [18]},\n",
       " 'field': {'soccer': [20],\n",
       "  'computer science': [27, 48],\n",
       "  'data science': [4, 70]},\n",
       " 'pitch': {'soccer': [22]},\n",
       " 'objective': {'soccer': [23]},\n",
       " 'score': {'soccer': [25, 76]},\n",
       " 'goal': {'soccer': [26, 32, 34, 77, 81, 86, 121, 130]},\n",
       " 'moving': {'soccer': [29]},\n",
       " 'beyond': {'soccer': [31]},\n",
       " 'line': {'soccer': [33, 87]},\n",
       " 'defended': {'soccer': [35]},\n",
       " 'opponent': {'soccer': [36]},\n",
       " 'traditionally': {'soccer': [37]},\n",
       " 'total': {'soccer': [42]},\n",
       " 'time': {'soccer': [44, 143]},\n",
       " 'minute': {'soccer': [45]},\n",
       " 'estimated': {'soccer': [46]},\n",
       " 'million': {'soccer': [47]},\n",
       " 'active': {'soccer': [49]},\n",
       " 'country': {'soccer': [50, 171]},\n",
       " 'territory': {'soccer': [51]},\n",
       " 'accordance': {'soccer': [58, 177]},\n",
       " 'law': {'soccer': [59, 178]},\n",
       " 'rule': {'soccer': [62]},\n",
       " 'effect': {'soccer': [63]},\n",
       " 'maintained': {'soccer': [65]},\n",
       " 'ifab': {'soccer': [66]},\n",
       " 'cm': {'soccer': [71]},\n",
       " 'circumference': {'soccer': [72]},\n",
       " 'compete': {'soccer': [75]},\n",
       " 'getting': {'soccer': [78]},\n",
       " 'post': {'soccer': [82]},\n",
       " 'bar': {'soccer': [83]},\n",
       " 'fully': {'soccer': [84]},\n",
       " 'mainly': {'soccer': [91]},\n",
       " 'part': {'soccer': [97]},\n",
       " 'body': {'soccer': [98]},\n",
       " 'except': {'soccer': [99]},\n",
       " 'hand': {'soccer': [100, 114]},\n",
       " 'arm': {'soccer': [101, 115]},\n",
       " 'control': {'soccer': [102]},\n",
       " 'pas': {'soccer': [104]},\n",
       " 'head': {'soccer': [106]},\n",
       " 'chest': {'soccer': [107]},\n",
       " 'thigh': {'soccer': [108]},\n",
       " 'goalkeeper': {'soccer': [111]},\n",
       " 'penalty': {'soccer': [117, 144]},\n",
       " 'area': {'soccer': [118], 'computer science': [96]},\n",
       " 'winner': {'soccer': [124], 'data science': [91]},\n",
       " 'depending': {'soccer': [125]},\n",
       " 'format': {'soccer': [126]},\n",
       " 'competition': {'soccer': [127, 176, 183, 197]},\n",
       " 'equal': {'soccer': [128]},\n",
       " 'number': {'soccer': [129]},\n",
       " 'result': {'soccer': [133]},\n",
       " 'draw': {'soccer': [134]},\n",
       " 'declared': {'soccer': [135]},\n",
       " 'awarded': {'soccer': [137]},\n",
       " 'go': {'soccer': [141]},\n",
       " 'extra': {'soccer': [142]},\n",
       " 'internationally': {'soccer': [145]},\n",
       " 'governed': {'soccer': [148]},\n",
       " 'fifa': {'soccer': [149, 150, 184]},\n",
       " 'six': {'soccer': [151]},\n",
       " 'continental': {'soccer': [152]},\n",
       " 'confederation': {'soccer': [153]},\n",
       " 'afc': {'soccer': [154]},\n",
       " 'caf': {'soccer': [155]},\n",
       " 'concacaf': {'soccer': [156]},\n",
       " 'conmebol': {'soccer': [157]},\n",
       " 'ofc': {'soccer': [158]},\n",
       " 'uefa': {'soccer': [159, 201]},\n",
       " 'national': {'soccer': [160]},\n",
       " 'fa': {'soccer': [162]},\n",
       " 'england': {'soccer': [163]},\n",
       " 'united': {'soccer': [165]},\n",
       " 'state': {'soccer': [166]},\n",
       " 'etc': {'soccer': [167]},\n",
       " 'responsible': {'soccer': [168]},\n",
       " 'managing': {'soccer': [169]},\n",
       " 'professionally': {'soccer': [172]},\n",
       " 'amateur': {'soccer': [173]},\n",
       " 'coordinating': {'soccer': [175]},\n",
       " 'prestigious': {'soccer': [180, 196]},\n",
       " 'senior': {'soccer': [181]},\n",
       " 'international': {'soccer': [182]},\n",
       " 'cup': {'soccer': [186, 189]},\n",
       " 'sporting': {'soccer': [190, 214]},\n",
       " 'surpassing': {'soccer': [193]},\n",
       " 'club': {'soccer': [199]},\n",
       " 'champion': {'soccer': [202, 211]},\n",
       " 'league': {'soccer': [203, 212]},\n",
       " 'attracts': {'soccer': [204]},\n",
       " 'extensive': {'soccer': [205]},\n",
       " 'television': {'soccer': [206]},\n",
       " 'audience': {'soccer': [207]},\n",
       " 'worldwide': {'soccer': [208]},\n",
       " 'final': {'soccer': [209]},\n",
       " 'annual': {'soccer': [213]},\n",
       " 'computer': {'computer science': [0,\n",
       "   9,\n",
       "   29,\n",
       "   35,\n",
       "   50,\n",
       "   60,\n",
       "   86,\n",
       "   108,\n",
       "   112,\n",
       "   132,\n",
       "   151,\n",
       "   161],\n",
       "  'data science': [75, 85]},\n",
       " 'science': {'computer science': [1, 8, 10, 36, 152, 162],\n",
       "  'data science': [1, 25, 34, 39, 42, 51, 76, 78, 83, 86, 88, 96, 99, 105]},\n",
       " 'study': {'computer science': [2]},\n",
       " 'computation': {'computer science': [3, 16, 38, 42]},\n",
       " 'information': {'computer science': [4, 17],\n",
       "  'data science': [35, 77, 87, 108]},\n",
       " 'automation': {'computer science': [5]},\n",
       " 'included': {'computer science': [6]},\n",
       " 'broadly': {'computer science': [7]},\n",
       " 'span': {'computer science': [11]},\n",
       " 'theoretical': {'computer science': [12], 'data science': [101]},\n",
       " 'discipline': {'computer science': [13, 20], 'data science': [47]},\n",
       " 'algorithm': {'computer science': [14, 31], 'data science': [14]},\n",
       " 'theory': {'computer science': [15, 18, 37, 69, 77], 'data science': [67]},\n",
       " 'applied': {'computer science': [19]},\n",
       " 'implementation': {'computer science': [23]},\n",
       " 'hardware': {'computer science': [24]},\n",
       " 'software': {'computer science': [25, 88, 95]},\n",
       " 'expert': {'computer science': [26]},\n",
       " 'scientist': {'computer science': [30], 'data science': [113]},\n",
       " 'data': {'computer science': [32, 81, 139, 148],\n",
       "  'data science': [0, 23, 24, 38, 50, 55, 64, 82, 95, 110, 112, 122]},\n",
       " 'structure': {'computer science': [33]},\n",
       " 'central': {'computer science': [34]},\n",
       " 'concern': {'computer science': [39, 78, 150]},\n",
       " 'abstract': {'computer science': [40]},\n",
       " 'model': {'computer science': [41]},\n",
       " 'general': {'computer science': [43]},\n",
       " 'class': {'computer science': [44]},\n",
       " 'problem': {'computer science': [45]},\n",
       " 'solved': {'computer science': [46]},\n",
       " 'cryptography': {'computer science': [49]},\n",
       " 'security': {'computer science': [51, 58]},\n",
       " 'involve': {'computer science': [52]},\n",
       " 'studying': {'computer science': [53]},\n",
       " 'mean': {'computer science': [54]},\n",
       " 'secure': {'computer science': [55]},\n",
       " 'communication': {'computer science': [56]},\n",
       " 'preventing': {'computer science': [57]},\n",
       " 'vulnerability': {'computer science': [59]},\n",
       " 'graphic': {'computer science': [61]},\n",
       " 'computational': {'computer science': [62, 74], 'data science': [102]},\n",
       " 'geometry': {'computer science': [63]},\n",
       " 'address': {'computer science': [64]},\n",
       " 'generation': {'computer science': [65]},\n",
       " 'image': {'computer science': [66, 137]},\n",
       " 'considers': {'computer science': [70]},\n",
       " 'different': {'computer science': [71], 'data science': [84]},\n",
       " 'way': {'computer science': [72]},\n",
       " 'describe': {'computer science': [73]},\n",
       " 'process': {'computer science': [75, 121, 136, 145]},\n",
       " 'database': {'computer science': [76]},\n",
       " 'management': {'computer science': [79]},\n",
       " 'repository': {'computer science': [80]},\n",
       " 'interaction': {'computer science': [82]},\n",
       " 'investigates': {'computer science': [83]},\n",
       " 'interface': {'computer science': [84]},\n",
       " 'human': {'computer science': [85, 127]},\n",
       " 'interact': {'computer science': [87]},\n",
       " 'engineering': {'computer science': [89]},\n",
       " 'focus': {'computer science': [90]},\n",
       " 'principle': {'computer science': [92, 103]},\n",
       " 'behind': {'computer science': [93, 105]},\n",
       " 'developing': {'computer science': [94]},\n",
       " 'operating': {'computer science': [97]},\n",
       " 'system': {'computer science': [98, 101, 107], 'data science': [15]},\n",
       " 'network': {'computer science': [99]},\n",
       " 'embedded': {'computer science': [100]},\n",
       " 'investigate': {'computer science': [102]},\n",
       " 'complex': {'computer science': [106]},\n",
       " 'architecture': {'computer science': [109]},\n",
       " 'describes': {'computer science': [110]},\n",
       " 'construction': {'computer science': [111]},\n",
       " 'component': {'computer science': [113]},\n",
       " 'equipment': {'computer science': [114]},\n",
       " 'artificial': {'computer science': [115, 130]},\n",
       " 'intelligence': {'computer science': [116, 131]},\n",
       " 'aim': {'computer science': [119, 134, 143]},\n",
       " 'synthesize': {'computer science': [120]},\n",
       " 'environmental': {'computer science': [122]},\n",
       " 'adaptation': {'computer science': [123]},\n",
       " 'planning': {'computer science': [124]},\n",
       " 'found': {'computer science': [126]},\n",
       " 'animal': {'computer science': [128]},\n",
       " 'vision': {'computer science': [133]},\n",
       " 'understand': {'computer science': [135, 144], 'data science': [60]},\n",
       " 'video': {'computer science': [138]},\n",
       " 'natural': {'computer science': [140], 'data science': [33]},\n",
       " 'processing': {'computer science': [142], 'data science': [11]},\n",
       " 'textual': {'computer science': [146]},\n",
       " 'linguistic': {'computer science': [147]},\n",
       " 'fundamental': {'computer science': [149]},\n",
       " 'determining': {'computer science': [153]},\n",
       " 'automated': {'computer science': [154]},\n",
       " 'turing': {'computer science': [155], 'data science': [89]},\n",
       " 'award': {'computer science': [156], 'data science': [90]},\n",
       " 'generally': {'computer science': [157]},\n",
       " 'recognized': {'computer science': [158]},\n",
       " 'highest': {'computer science': [159]},\n",
       " 'distinction': {'computer science': [160]},\n",
       " 'interdisciplinary': {'data science': [2]},\n",
       " 'academic': {'data science': [3]},\n",
       " 'us': {'data science': [5, 65]},\n",
       " 'statistic': {'data science': [6, 54, 74]},\n",
       " 'scientific': {'data science': [7, 9, 12]},\n",
       " 'computing': {'data science': [8]},\n",
       " 'method': {'data science': [10, 46, 59]},\n",
       " 'visualization': {'data science': [13]},\n",
       " 'extract': {'data science': [16]},\n",
       " 'extrapolate': {'data science': [17]},\n",
       " 'knowledge': {'data science': [18, 29, 80, 120]},\n",
       " 'potentially': {'data science': [19]},\n",
       " 'noisy': {'data science': [20]},\n",
       " 'unstructured': {'data science': [22]},\n",
       " 'integrates': {'data science': [27]},\n",
       " 'domain': {'data science': [28, 32, 79]},\n",
       " 'underlying': {'data science': [30]},\n",
       " 'application': {'data science': [31]},\n",
       " 'technology': {'data science': [36, 109]},\n",
       " 'medicine': {'data science': [37]},\n",
       " 'multifaceted': {'data science': [40]},\n",
       " 'described': {'data science': [41]},\n",
       " 'research': {'data science': [43, 45]},\n",
       " 'workflow': {'data science': [48]},\n",
       " 'profession': {'data science': [49]},\n",
       " 'concept': {'data science': [52]},\n",
       " 'unify': {'data science': [53]},\n",
       " 'analysis': {'data science': [56]},\n",
       " 'informatics': {'data science': [57]},\n",
       " 'related': {'data science': [58]},\n",
       " 'analyze': {'data science': [61]},\n",
       " 'actual': {'data science': [62]},\n",
       " 'phenomenon': {'data science': [63]},\n",
       " 'technique': {'data science': [66]},\n",
       " 'drawn': {'data science': [68]},\n",
       " 'context': {'data science': [72]},\n",
       " 'mathematics': {'data science': [73]},\n",
       " 'however': {'data science': [81]},\n",
       " 'jim': {'data science': [92]},\n",
       " 'gray': {'data science': [93]},\n",
       " 'imagined': {'data science': [94]},\n",
       " 'fourth': {'data science': [97]},\n",
       " 'empirical': {'data science': [100]},\n",
       " 'asserted': {'data science': [103]},\n",
       " 'everything': {'data science': [104]},\n",
       " 'changing': {'data science': [106]},\n",
       " 'impact': {'data science': [107]},\n",
       " 'deluge': {'data science': [111]},\n",
       " 'creates': {'data science': [115]},\n",
       " 'combine': {'data science': [118]},\n",
       " 'statistical': {'data science': [119]},\n",
       " 'summarize': {'data science': [121]}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#code/program Task 3\n",
    "# This inverted index would need to have the term as keys, \n",
    "# and another dictionary as values with the document title as keys,\n",
    "# and a list of word-level indexes as values\n",
    "inverted_index = {}\n",
    "\n",
    "for title, tokens in lemma_tokenized_documents.items():\n",
    "    for position, token in enumerate(tokens):\n",
    "        if token not in inverted_index:\n",
    "            inverted_index[token] = {}\n",
    "        if title not in inverted_index[token]:\n",
    "            inverted_index[token][title] = []\n",
    "        inverted_index[token][title].append(position)\n",
    "\n",
    "inverted_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a211565-df63-45a8-a490-6469e8fe3d6e",
   "metadata": {},
   "source": [
    "## üìà Part B: Evaluation of IR Systems\n",
    "### Task 4: Implement Precision, Recall, and F1\n",
    "\n",
    "- Define a set of queries and manually label relevant documents.\n",
    "- Retrieve documents using keyword matching or TF-IDF ranking.\n",
    "- Compute:\n",
    "  - Precision  \n",
    "  - Recall  \n",
    "  - F1 Score  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f346f72-6f93-445d-9124-e0a44ca0d6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code/program Task 4\n",
    "# This dictionary maps 5 chosen queries to their relevant documents\n",
    "queries_mapped_to_relevant_documents = {\"how to start programming\":[\"python (programming language)\",\n",
    "                                                                    \"computer science\",\"data science\"],\n",
    "                                        \"what is a good sport to play\":[\"badminton\",\"soccer\"],\n",
    "                                        \"how to code using computer\":[\"python (programming language)\",\n",
    "                                                                      \"computer science\",\"data science\"],\n",
    "                                        \"how to kick a ball\":[\"soccer\"],\n",
    "                                        \"coding project ideas\":[\"python (programming language)\",\n",
    "                                                                \"computer science\",\"data science\"],\n",
    "                                        \"best world cup goals\":[\"soccer\"],\n",
    "                                        \"sports that require cardio\":[\"soccer\",\"badminton\"],\n",
    "                                        \"what language should i learn\":[\"python (programming language)\",\n",
    "                                                                        \"computer science\"],\n",
    "                                        \"what is a fun game i can play with friends\":[\"soccer\",\"badminton\"],\n",
    "                                        \"what do professional daily routines look like\":[\"soccer\",\"badminton\",\n",
    "                                                                                         \"data science\"]}\n",
    "query_list = list(queries_mapped_to_relevant_documents.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b80f2f7-405c-4361-b51a-7b5d52964772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keyword Matching algorithm\n",
    "def keyword(query, corpus):\n",
    "    query_words = query.lower().split()\n",
    "    res = []\n",
    "\n",
    "    for title, token_list in corpus.items():\n",
    "        # count the occurences of keyword (Using lemmatized documents for more accurate performance of search)\n",
    "        keyword_count = 0\n",
    "        for word in query_words:\n",
    "            keyword_count += token_list.count(word)\n",
    "\n",
    "        if keyword_count > 0:\n",
    "            res.append(title)\n",
    "    \n",
    "    res.sort(key=lambda x:x[1], reverse=True)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8cb8f8b-6034-424c-b9f9-fd9351570da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how to start programming: ['python (programming language)', 'computer science', 'data science']\n",
      "what is a good sport to play: ['soccer', 'badminton']\n",
      "how to code using computer: ['python (programming language)', 'computer science', 'badminton', 'data science']\n",
      "how to kick a ball: ['soccer', 'badminton']\n",
      "coding project ideas: []\n",
      "best world cup goals: ['soccer', 'badminton']\n",
      "sports that require cardio: ['badminton']\n",
      "what language should i learn: ['python (programming language)', 'computer science', 'badminton']\n",
      "what is a fun game i can play with friends: ['soccer', 'badminton']\n",
      "what do professional daily routines look like: ['badminton', 'data science']\n"
     ]
    }
   ],
   "source": [
    "# RESULTS OF KEYWORD SEARCH PER QUERY\n",
    "for query in queries_mapped_to_relevant_documents.keys():\n",
    "    print(f\"{query}: {keyword(query, lemma_tokenized_documents)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7869450b-75b0-4e72-b51b-e82883c92f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1-how to start programming: precision = 1.000, recall = 1.000, f1 = 1.000\n",
      "Q2-what is a good sport to play: precision = 1.000, recall = 1.000, f1 = 1.000\n",
      "Q3-how to code using computer: precision = 0.750, recall = 1.000, f1 = 0.857\n",
      "Q4-how to kick a ball: precision = 0.500, recall = 1.000, f1 = 0.667\n",
      "Q5-coding project ideas: precision = 0.000, recall = 0.000, f1 = 0.000\n",
      "Q6-best world cup goals: precision = 0.500, recall = 1.000, f1 = 0.667\n",
      "Q7-sports that require cardio: precision = 1.000, recall = 0.500, f1 = 0.667\n",
      "Q8-what language should i learn: precision = 0.667, recall = 1.000, f1 = 0.800\n",
      "Q9-what is a fun game i can play with friends: precision = 1.000, recall = 1.000, f1 = 1.000\n",
      "Q10-what do professional daily routines look like: precision = 1.000, recall = 0.667, f1 = 0.800\n",
      "AVERAGES: precision = 0.742, recall = 0.817, f1 = 0.746\n"
     ]
    }
   ],
   "source": [
    "#### PRECISION, RECALL AND F1 SCORE\n",
    "\n",
    "# \"how to start programming\"\n",
    "Q1_precision = 3/3\n",
    "Q1_recall = 3/3\n",
    "Q1_F1 = 2*(Q1_precision*Q1_recall) / (Q1_precision+Q1_recall)\n",
    "\n",
    "# \"what is a good sport to play\"\n",
    "Q2_precision = 2/2\n",
    "Q2_recall = 2/2\n",
    "Q2_F1 = 2*(Q2_precision*Q2_recall) / (Q2_precision+Q2_recall)\n",
    "\n",
    "# \"how to code using computer\"\n",
    "Q3_precision = 3/4\n",
    "Q3_recall = 3/3\n",
    "Q3_F1 = 2*(Q3_precision*Q3_recall) / (Q3_precision+Q3_recall)\n",
    "\n",
    "# \"how to kick a ball\"\n",
    "Q4_precision = 1/2\n",
    "Q4_recall = 1/1\n",
    "Q4_F1 = 2*(Q4_precision*Q4_recall) / (Q4_precision+Q4_recall)\n",
    "\n",
    "# \"coding project ideas\"\n",
    "Q5_precision = 0/1\n",
    "Q5_recall = 0/3\n",
    "Q5_F1 = 2*(Q5_precision*Q5_recall) / (Q5_precision+Q5_recall+1)\n",
    "\n",
    "# best world cup goals\n",
    "Q6_precision = 1/2\n",
    "Q6_recall = 1/1\n",
    "Q6_F1 = 2*(Q6_precision*Q6_recall) / (Q6_precision+Q6_recall)\n",
    "\n",
    "# sports that require cardio\n",
    "Q7_precision = 1/1\n",
    "Q7_recall = 1/2\n",
    "Q7_F1 = 2*(Q7_precision*Q7_recall) / (Q7_precision+Q7_recall)\n",
    "\n",
    "# what language should i learn\n",
    "Q8_precision = 2/3\n",
    "Q8_recall = 2/2\n",
    "Q8_F1 = 2*(Q8_precision*Q8_recall) / (Q8_precision+Q8_recall)\n",
    "\n",
    "# what is a fun game i can play with friends\n",
    "Q9_precision = 2/2\n",
    "Q9_recall = 2/2\n",
    "Q9_F1 = 2*(Q9_precision*Q9_recall) / (Q9_precision+Q9_recall)\n",
    "\n",
    "# what do professional daily routines look like\n",
    "Q10_precision = 2/2\n",
    "Q10_recall = 2/3\n",
    "Q10_F1 = 2*(Q10_precision*Q10_recall) / (Q10_precision+Q10_recall)\n",
    "\n",
    "# Average metrics\n",
    "avg_precision = (Q1_precision + Q2_precision + Q3_precision + Q4_precision + Q5_precision + \n",
    "                 Q6_precision + Q7_precision + Q8_precision + Q9_precision + Q10_precision) / 10\n",
    "avg_recall = (Q1_recall + Q2_recall + Q3_recall + Q4_recall + Q5_recall + Q6_recall + Q7_recall + \n",
    "              Q8_recall + Q9_recall + Q10_recall) / 10\n",
    "avg_F1 = (Q1_F1 + Q2_F1 + Q3_F1 + Q4_F1 + Q5_F1 + Q6_F1 + Q7_F1 + Q8_F1 + Q9_F1 + Q10_F1) / 10\n",
    "\n",
    "print(f\"Q1-{query_list[0]}: precision = {Q1_precision:.3f}, recall = {Q1_recall:.3f}, f1 = {Q1_F1:.3f}\")\n",
    "print(f\"Q2-{query_list[1]}: precision = {Q2_precision:.3f}, recall = {Q2_recall:.3f}, f1 = {Q2_F1:.3f}\")\n",
    "print(f\"Q3-{query_list[2]}: precision = {Q3_precision:.3f}, recall = {Q3_recall:.3f}, f1 = {Q3_F1:.3f}\")\n",
    "print(f\"Q4-{query_list[3]}: precision = {Q4_precision:.3f}, recall = {Q4_recall:.3f}, f1 = {Q4_F1:.3f}\")\n",
    "print(f\"Q5-{query_list[4]}: precision = {Q5_precision:.3f}, recall = {Q5_recall:.3f}, f1 = {Q5_F1:.3f}\")\n",
    "print(f\"Q6-{query_list[5]}: precision = {Q6_precision:.3f}, recall = {Q6_recall:.3f}, f1 = {Q6_F1:.3f}\")\n",
    "print(f\"Q7-{query_list[6]}: precision = {Q7_precision:.3f}, recall = {Q7_recall:.3f}, f1 = {Q7_F1:.3f}\")\n",
    "print(f\"Q8-{query_list[7]}: precision = {Q8_precision:.3f}, recall = {Q8_recall:.3f}, f1 = {Q8_F1:.3f}\")\n",
    "print(f\"Q9-{query_list[8]}: precision = {Q9_precision:.3f}, recall = {Q9_recall:.3f}, f1 = {Q9_F1:.3f}\")\n",
    "print(f\"Q10-{query_list[9]}: precision = {Q10_precision:.3f}, recall = {Q10_recall:.3f}, f1 = {Q10_F1:.3f}\")\n",
    "print(f\"AVERAGES: precision = {avg_precision:.3f}, recall = {avg_recall:.3f}, f1 = {avg_F1:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d436bf06-16a2-4a63-8be1-5f7e19ee1f3c",
   "metadata": {},
   "source": [
    "### Task 5: Precision@k and MAP\n",
    "\n",
    "- Rank documents using cosine similarity.\n",
    "- Evaluate Precision@5 and MAP across multiple queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "158a8d78-cd08-4c13-b820-4facf8552cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code/program Task 5\n",
    "import math\n",
    "# COSINE SIMILARITY\n",
    "def cosine_similarity(query, corpus):\n",
    "    # Find Term frequency for each document and term, including query\n",
    "    freq_dict  = {}\n",
    "    document_titles = list(corpus.keys())\n",
    "    \n",
    "    for idx, title in enumerate(document_titles):\n",
    "        list_words = corpus[title]\n",
    "        for word in list_words:\n",
    "            if word not in freq_dict:\n",
    "                freq_dict[word] = [0] * len(corpus)\n",
    "            freq_dict[word][idx] += 1\n",
    "\n",
    "    # Cosine Similarity\n",
    "    # prepare document and query vectors\n",
    "    vocabulary = freq_dict.keys()\n",
    "\n",
    "    document_vectors = []\n",
    "    for title in document_titles:\n",
    "        words = corpus[title]\n",
    "        vector = [words.count(term) for term in vocabulary]\n",
    "        document_vectors.append(vector)\n",
    "\n",
    "    query_vector = [query.split().count(term) for term in vocabulary]\n",
    "    \n",
    "    # 5b: calculate similarity between query and each document\n",
    "    cosine_similarities = []\n",
    "    for idx,doc_vec in enumerate(document_vectors):\n",
    "        dot_prod = sum(x*y for x,y in zip(doc_vec, query_vector))\n",
    "        doc_norm = math.sqrt(sum(x*x for x in doc_vec))\n",
    "        query_norm = math.sqrt(sum(x*x for x in query_vector))\n",
    "        # Division by 0 error handling\n",
    "        if doc_norm == 0 or query_norm == 0:\n",
    "            cs = 0\n",
    "        else:\n",
    "            cs = round(dot_prod / (doc_norm*query_norm),3)\n",
    "        cosine_similarities.append((document_titles[idx],cs))\n",
    "\n",
    "    cosine_similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    return cosine_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2e94b2a-e041-418d-a17d-2afc658e233e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('python (programming language)', 0.499),\n",
       " ('computer science', 0.048),\n",
       " ('data science', 0.045),\n",
       " ('badminton', 0.0),\n",
       " ('soccer', 0.0)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cosine Similarity on first query\n",
    "cosine_similarity(\"how to start programming\", lemma_tokenized_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38d2782a-b4c1-4b0b-ba09-bca97e970f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how to start programming PRECISION@5: 0.6\n",
      "what is a good sport to play PRECISION@5: 0.4\n",
      "how to code using computer PRECISION@5: 0.6\n",
      "how to kick a ball PRECISION@5: 0.2\n",
      "coding project ideas PRECISION@5: 0.6\n",
      "best world cup goals PRECISION@5: 0.2\n",
      "sports that require cardio PRECISION@5: 0.4\n",
      "what language should i learn PRECISION@5: 0.4\n",
      "what is a fun game i can play with friends PRECISION@5: 0.4\n",
      "what do professional daily routines look like PRECISION@5: 0.6\n"
     ]
    }
   ],
   "source": [
    "# Precision@5 for all queries\n",
    "def precision_at_5(relevant_docs_for_query, search_results, k=5):\n",
    "    topk = search_results[:k]\n",
    "\n",
    "    topk_docs = [doc for doc, score in topk]\n",
    "\n",
    "    rel_topk = sum(1 for doc in topk_docs if doc in relevant_docs_for_query)\n",
    "\n",
    "    precision_k = rel_topk / k\n",
    "\n",
    "    return precision_k\n",
    "\n",
    "for query in queries_mapped_to_relevant_documents.keys():\n",
    "    relevant_docs_for_query = queries_mapped_to_relevant_documents[query]\n",
    "    print(f\"{query} PRECISION@5: {precision_at_5(relevant_docs_for_query,\n",
    "                                  cosine_similarity(query, lemma_tokenized_documents))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9cdb5837-9cb9-4f87-95bd-c104cde7be9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP SCORE = 0.945\n"
     ]
    }
   ],
   "source": [
    "# AVERAGE PRECISION\n",
    "def avg_precision(relevant_docs_for_query, search_results):\n",
    "    if len(relevant_docs_for_query) == 0:\n",
    "        return 0\n",
    "\n",
    "    precision_list = []\n",
    "    relevant_doc_count = 0\n",
    "\n",
    "    for idx, (doc, score) in enumerate(search_results):\n",
    "        if doc in relevant_docs_for_query:\n",
    "            relevant_doc_count += 1\n",
    "            precision_at_k = relevant_doc_count / (idx+1)\n",
    "            precision_list.append(precision_at_k)\n",
    "\n",
    "    if len(precision_list) == 0:\n",
    "        return 0\n",
    "\n",
    "    avg_precision = sum(precision_list) / len(relevant_docs_for_query)\n",
    "    return avg_precision\n",
    "\n",
    "# MAP\n",
    "APs = []\n",
    "for query in queries_mapped_to_relevant_documents.keys():\n",
    "    relevant_docs_for_query = queries_mapped_to_relevant_documents[query]\n",
    "    search_results = cosine_similarity(query, lemma_tokenized_documents)\n",
    "    average_precision = avg_precision(relevant_docs_for_query, search_results)\n",
    "    APs.append(average_precision)\n",
    "\n",
    "MAP = sum(APs) / len(APs)\n",
    "print(f\"MAP SCORE = {MAP}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a95934-a664-4610-b746-33cc079811c7",
   "metadata": {},
   "source": [
    "## üîÅ Part C: Relevance Feedback and Query Expansion\n",
    "### Task 6: Pseudo Relevance Feedback\n",
    "\n",
    "- Assume top-k retrieved documents are relevant.\n",
    "- Extract frequent terms and expand the query.\n",
    "- Re-run retrieval and compare performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6c0abe7-8a63-4f90-abe2-276e5a9d93dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how to kick a ball game sport team shuttlecock played\n",
      "how to code using computer science data programming language python\n",
      "what do professional daily routines look like science data sport shuttlecock programming\n"
     ]
    }
   ],
   "source": [
    "#code/program Task 6\n",
    "# Using three queries for PRF\n",
    "queries_used_3 = {\"how to kick a ball\":[\"soccer\"],\n",
    "                  \"how to code using computer\":[\"python (programming language)\",\n",
    "                                                \"computer science\",\"data science\"],\n",
    "                  \"what do professional daily routines look like\":[\"soccer\",\"badminton\",\"data science\"]}\n",
    "query_3_list = list(queries_used_3.keys())\n",
    "\n",
    "for query in queries_used_3.keys():\n",
    "    relevant_docs = queries_used_3[query]\n",
    "    # Initial values\n",
    "    init_res = cosine_similarity(query, lemma_tokenized_documents)\n",
    "\n",
    "    # Using top 3 docs as relevant\n",
    "    top3 = init_res[:3]\n",
    "    terms = []\n",
    "    for doc, _ in top3:\n",
    "        terms.extend(lemma_tokenized_documents[doc])\n",
    "\n",
    "    # get top 5 new terms\n",
    "    query_tokens = set(query.split())\n",
    "    term_frequency = {}\n",
    "    for term in terms:\n",
    "        if term not in query_tokens:\n",
    "            term_frequency[term] = term_frequency.get(term, 0) + 1\n",
    "\n",
    "    # sort by frqeuncy\n",
    "    sorted_terms = sorted(term_frequency.items(), key=lambda x:x[1], reverse=True)\n",
    "    new_terms = [term for term, freq in sorted_terms[:5]]\n",
    "    expanded_query = query + \" \" +\" \".join(new_terms)\n",
    "    print(expanded_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97a9095e-173f-4e63-8b60-9ba2c75f18f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_at_3(relevant_docs_for_query, search_results, k=3):\n",
    "    topk = search_results[:k]\n",
    "    topk_docs = [doc for doc, score in topk]\n",
    "    rel_topk = sum(1 for doc in topk_docs if doc in relevant_docs_for_query)\n",
    "    if len(relevant_docs_for_query) == 0:\n",
    "        recall_k = 0\n",
    "    else:\n",
    "        recall_k = rel_topk / len(relevant_docs_for_query)\n",
    "    return recall_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59d4d927-cdb4-4c35-b8c4-47e47667f10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how to kick a ball P@3:0.3333333333333333\n",
      "how to kick a ball game sport team shuttlecock played P@3:0.3333333333333333\n",
      "\n",
      "how to code using computer P@3:1.0\n",
      "how to code using computer science data programming language python P@3:1.0\n",
      "\n",
      "what do professional daily routines look like P@3:0.6666666666666666\n",
      "what do professional daily routines look like science data sport shuttlecock programming P@3:0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "queries_used_ref_3 = {\"how to kick a ball game sport team shuttlecock played\":[\"soccer\"],\n",
    "        \"how to code using computer science data programming language python\":[\"python (programming language)\",\n",
    "                                                                            \"computer science\",\"data science\"],\n",
    "        \"what do professional daily routines look like science data sport shuttlecock programming\":[\"soccer\",\n",
    "                                                                                \"badminton\",\"data science\"]}\n",
    "# USING PRECISION@3 BY MAKING K=3\n",
    "query_3_list = list(queries_used_3.keys())\n",
    "query_3_ref_list = list(queries_used_ref_3.keys())\n",
    "\n",
    "print(f\"{query_3_list[0]} P@3:{precision_at_5(queries_used_3[query_3_list[0]], \n",
    "                                    cosine_similarity(query_3_list[0], lemma_tokenized_documents),k=3)}\")\n",
    "print(f\"{query_3_ref_list[0]} P@3:{precision_at_5(queries_used_ref_3[query_3_ref_list[0]], \n",
    "                                    cosine_similarity(query_3_ref_list[0], lemma_tokenized_documents),k=3)}\")\n",
    "print()\n",
    "print(f\"{query_3_list[1]} P@3:{precision_at_5(queries_used_3[query_3_list[1]], \n",
    "                                    cosine_similarity(query_3_list[1], lemma_tokenized_documents),k=3)}\")\n",
    "print(f\"{query_3_ref_list[1]} P@3:{precision_at_5(queries_used_ref_3[query_3_ref_list[1]], \n",
    "                                    cosine_similarity(query_3_ref_list[1], lemma_tokenized_documents),k=3)}\")\n",
    "print()\n",
    "print(f\"{query_3_list[2]} P@3:{precision_at_5(queries_used_3[query_3_list[2]], \n",
    "                                    cosine_similarity(query_3_list[2], lemma_tokenized_documents),k=3)}\")\n",
    "print(f\"{query_3_ref_list[2]} P@3:{precision_at_5(queries_used_ref_3[query_3_ref_list[2]], \n",
    "                                    cosine_similarity(query_3_ref_list[2], lemma_tokenized_documents),k=3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "25553c86-5caf-4ff3-9912-d3edf7aae3ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how to kick a ball R@3:1.0\n",
      "how to kick a ball game sport team shuttlecock played R@3:1.0\n",
      "\n",
      "how to code using computer R@3:1.0\n",
      "how to code using computer science data programming language python R@3:1.0\n",
      "\n",
      "what do professional daily routines look like R@3:0.6666666666666666\n",
      "what do professional daily routines look like science data sport shuttlecock programming R@3:0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "# RECALL@3\n",
    "print(f\"{query_3_list[0]} R@3:{recall_at_3(queries_used_3[query_3_list[0]], \n",
    "                                    cosine_similarity(query_3_list[0], lemma_tokenized_documents),k=3)}\")\n",
    "print(f\"{query_3_ref_list[0]} R@3:{recall_at_3(queries_used_ref_3[query_3_ref_list[0]], \n",
    "                                    cosine_similarity(query_3_ref_list[0], lemma_tokenized_documents),k=3)}\")\n",
    "print()\n",
    "print(f\"{query_3_list[1]} R@3:{recall_at_3(queries_used_3[query_3_list[1]], \n",
    "                                    cosine_similarity(query_3_list[1], lemma_tokenized_documents),k=3)}\")\n",
    "print(f\"{query_3_ref_list[1]} R@3:{recall_at_3(queries_used_ref_3[query_3_ref_list[1]], \n",
    "                                    cosine_similarity(query_3_ref_list[1], lemma_tokenized_documents),k=3)}\")\n",
    "print()\n",
    "print(f\"{query_3_list[2]} R@3:{recall_at_3(queries_used_3[query_3_list[2]], \n",
    "                                    cosine_similarity(query_3_list[2], lemma_tokenized_documents),k=3)}\")\n",
    "print(f\"{query_3_ref_list[2]} R@3:{recall_at_3(queries_used_ref_3[query_3_ref_list[2]], \n",
    "                                    cosine_similarity(query_3_ref_list[2], lemma_tokenized_documents),k=3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b840fdea-cdbe-49b5-946e-d443524d5344",
   "metadata": {},
   "source": [
    "### Task 7: Query Expansion Techniques\n",
    "\n",
    "- Apply synonym expansion using WordNet.\n",
    "- Use local analysis to extract terms from top-ranked documents.\n",
    "- Compare original vs. expanded query results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7b35e047-58e8-4573-95af-78b78e561617",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code/program Task 7\n",
    "# SYNONYM EXAPNSION USING WORDNET\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "# We will once again use these three queries\n",
    "queries_used_3 = {\n",
    "    \"how to kick a ball\":[\"soccer\"],\n",
    "    \"how to code using computer\":[\"python (programming language)\",\"computer science\",\"data science\"],\n",
    "    \"what do professional daily routines look like\":[\"soccer\",\"badminton\",\"data science\"]\n",
    "}\n",
    "\n",
    "def query_synonym_expansion(query):\n",
    "    tokens = query.lower().split()\n",
    "    # Remove stopwords, and tokenize\n",
    "    tokens = [token for token in tokens if token not in stopwords]\n",
    "    expanded_query = []\n",
    "\n",
    "    for token in tokens:\n",
    "        expanded_query.append(token)\n",
    "\n",
    "        synonyms = []\n",
    "        for set_of_synonyms in wordnet.synsets(token):\n",
    "            for lemma in set_of_synonyms.lemmas():\n",
    "                synonym_words = lemma.name().lower()\n",
    "                if synonym_words != token:\n",
    "                    synonyms.append(synonym_words)\n",
    "\n",
    "        expanded_query.extend(list(set(synonyms)))\n",
    "    return \" \".join(expanded_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4deaf01a-d99c-49b7-b8af-83839526054c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kick kicking flush quetch plain thrill bitch kick_back rush charge bang boot recoil gripe sound_off kvetch give_up complain beef squawk ball musket_ball lucille_ball orb formal orchis clod bollock glob chunk ballock egg lump nut testicle globe clump testis': ['soccer'],\n",
       " 'code encipher codification encrypt cypher inscribe write_in_code computer_code cipher using apply victimization victimisation expend practice utilise habituate use employ exploitation utilize computer computing_machine estimator calculator computing_device reckoner electronic_computer figurer information_processing_system data_processor': ['python (programming language)',\n",
       "  'computer science',\n",
       "  'data science'],\n",
       " 'professional pro professional_person master daily day-to-day day-by-day casual everyday day_by_day day-after-day routines modus_operandi act procedure subprogram function subroutine turn routine bit number look take_care see wait spirit aspect depend face appear feeling reckon flavour calculate bet tone smell count expression looking facial_expression feel seem attend looking_at front expect search await flavor like alike comparable wish the_like ilk similar the_likes_of care same corresponding': ['soccer',\n",
       "  'badminton',\n",
       "  'data science']}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synonym_expansion = dict()\n",
    "for query in queries_used_3.keys():\n",
    "    synonyms = query_synonym_expansion(query)\n",
    "    synonym_expansion[synonyms] = queries_used_3[query]\n",
    "synonym_expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2c11a6bb-c793-420c-bd96-eb70b63fd0c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'how to kick a ball game sport team shuttlecock played': ['soccer'],\n",
       " 'how to code using computer science data programming language python': ['python (programming language)',\n",
       "  'computer science',\n",
       "  'data science'],\n",
       " 'what do professional daily routines look like science data sport shuttlecock programming': ['soccer',\n",
       "  'badminton',\n",
       "  'data science']}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LOCAL ANALYSIS\n",
    "local_analysis = dict()\n",
    "for query in queries_used_3.keys():\n",
    "    relevant_docs = queries_used_3[query]\n",
    "    # Initial values\n",
    "    init_res = cosine_similarity(query, lemma_tokenized_documents)\n",
    "\n",
    "    # Using top 3 docs as relevant\n",
    "    top3 = init_res[:3]\n",
    "    terms = []\n",
    "    for doc, _ in top3:\n",
    "        terms.extend(lemma_tokenized_documents[doc])\n",
    "\n",
    "    # get top 5 new terms\n",
    "    query_tokens = set(query.split())\n",
    "    term_frequency = {}\n",
    "    for term in terms:\n",
    "        if term not in query_tokens:\n",
    "            term_frequency[term] = term_frequency.get(term, 0) + 1\n",
    "\n",
    "    # sort by frqeuncy\n",
    "    sorted_terms = sorted(term_frequency.items(), key=lambda x:x[1], reverse=True)\n",
    "    new_terms = [term for term, freq in sorted_terms[:5]]\n",
    "    expanded_query = query + \" \" +\" \".join(new_terms)\n",
    "    local_analysis[expanded_query] = queries_used_3[query]\n",
    "local_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f1efe16e-3051-45c6-8ae4-7a5399f8220c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUERY 1 RESULTS:\n",
      "kick kicking flush quetch plain thrill bitch kick_back rush charge bang boot recoil gripe sound_off kvetch give_up complain beef squawk ball musket_ball lucille_ball orb formal orchis clod bollock glob chunk ballock egg lump nut testicle globe clump testis PRECISION@3: 0.3333333333333333\n",
      "\n",
      "how to kick a ball game sport team shuttlecock played PRECISION@3: 0.3333333333333333\n",
      "\n",
      "QUERY 2 RESULTS:\n",
      "code encipher codification encrypt cypher inscribe write_in_code computer_code cipher using apply victimization victimisation expend practice utilise habituate use employ exploitation utilize computer computing_machine estimator calculator computing_device reckoner electronic_computer figurer information_processing_system data_processor PRECISION@3: 0.6666666666666666\n",
      "\n",
      "how to code using computer science data programming language python PRECISION@3: 1.0\n",
      "\n",
      "QUERY 3 RESULTS:\n",
      "professional pro professional_person master daily day-to-day day-by-day casual everyday day_by_day day-after-day routines modus_operandi act procedure subprogram function subroutine turn routine bit number look take_care see wait spirit aspect depend face appear feeling reckon flavour calculate bet tone smell count expression looking facial_expression feel seem attend looking_at front expect search await flavor like alike comparable wish the_like ilk similar the_likes_of care same corresponding PRECISION@3: 0.6666666666666666\n",
      "\n",
      "what do professional daily routines look like science data sport shuttlecock programming PRECISION@3: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "# USING PRECISION@3 BY MAKING K=3\n",
    "queries_syn = list(synonym_expansion.keys())\n",
    "query_local = list(local_analysis.keys())\n",
    "\n",
    "print(\"QUERY 1 RESULTS:\")\n",
    "print(f\"{queries_syn[0]} PRECISION@3: {precision_at_5(synonym_expansion[queries_syn[0]], \n",
    "                                        cosine_similarity(queries_syn[0], lemma_tokenized_documents),k=3)}\")\n",
    "print()\n",
    "print(f\"{query_local[0]} PRECISION@3: {precision_at_5(local_analysis[query_local[0]], \n",
    "                                        cosine_similarity(query_local[0], lemma_tokenized_documents),k=3)}\")\n",
    "print()\n",
    "print(\"QUERY 2 RESULTS:\")\n",
    "print(f\"{queries_syn[1]} PRECISION@3: {precision_at_5(synonym_expansion[queries_syn[1]], \n",
    "                                        cosine_similarity(queries_syn[1], lemma_tokenized_documents),k=3)}\")\n",
    "print()\n",
    "print(f\"{query_local[1]} PRECISION@3: {precision_at_5(local_analysis[query_local[1]], \n",
    "                                        cosine_similarity(query_local[1], lemma_tokenized_documents),k=3)}\")\n",
    "print()\n",
    "print(\"QUERY 3 RESULTS:\")\n",
    "print(f\"{queries_syn[2]} PRECISION@3: {precision_at_5(synonym_expansion[queries_syn[2]], \n",
    "                                        cosine_similarity(queries_syn[2], lemma_tokenized_documents),k=3)}\")\n",
    "print()\n",
    "print(f\"{query_local[2]} PRECISION@3: {precision_at_5(local_analysis[query_local[2]], \n",
    "                                        cosine_similarity(query_local[2], lemma_tokenized_documents),k=3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "897b3223-95b8-4baf-bdb4-341e0ea0d4a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUERY 1 RESULTS:\n",
      "kick kicking flush quetch plain thrill bitch kick_back rush charge bang boot recoil gripe sound_off kvetch give_up complain beef squawk ball musket_ball lucille_ball orb formal orchis clod bollock glob chunk ballock egg lump nut testicle globe clump testis RECALL@3: 1.0\n",
      "\n",
      "how to kick a ball game sport team shuttlecock played RECALL@3: 1.0\n",
      "\n",
      "QUERY 2 RESULTS:\n",
      "code encipher codification encrypt cypher inscribe write_in_code computer_code cipher using apply victimization victimisation expend practice utilise habituate use employ exploitation utilize computer computing_machine estimator calculator computing_device reckoner electronic_computer figurer information_processing_system data_processor RECALL@3: 0.6666666666666666\n",
      "\n",
      "how to code using computer science data programming language python RECALL@3: 1.0\n",
      "\n",
      "QUERY 3 RESULTS:\n",
      "professional pro professional_person master daily day-to-day day-by-day casual everyday day_by_day day-after-day routines modus_operandi act procedure subprogram function subroutine turn routine bit number look take_care see wait spirit aspect depend face appear feeling reckon flavour calculate bet tone smell count expression looking facial_expression feel seem attend looking_at front expect search await flavor like alike comparable wish the_like ilk similar the_likes_of care same corresponding RECALL@3: 0.6666666666666666\n",
      "\n",
      "what do professional daily routines look like science data sport shuttlecock programming RECALL@3: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "# RECALL @ 3\n",
    "print(\"QUERY 1 RESULTS:\")\n",
    "print(f\"{queries_syn[0]} RECALL@3: {recall_at_3(synonym_expansion[queries_syn[0]], \n",
    "                                        cosine_similarity(queries_syn[0], lemma_tokenized_documents),k=3)}\")\n",
    "print()\n",
    "print(f\"{query_local[0]} RECALL@3: {recall_at_3(local_analysis[query_local[0]], \n",
    "                                        cosine_similarity(query_local[0], lemma_tokenized_documents),k=3)}\")\n",
    "print()\n",
    "print(\"QUERY 2 RESULTS:\")\n",
    "print(f\"{queries_syn[1]} RECALL@3: {recall_at_3(synonym_expansion[queries_syn[1]], \n",
    "                                        cosine_similarity(queries_syn[1], lemma_tokenized_documents),k=3)}\")\n",
    "print()\n",
    "print(f\"{query_local[1]} RECALL@3: {recall_at_3(local_analysis[query_local[1]], \n",
    "                                        cosine_similarity(query_local[1], lemma_tokenized_documents),k=3)}\")\n",
    "print()\n",
    "print(\"QUERY 3 RESULTS:\")\n",
    "print(f\"{queries_syn[2]} RECALL@3: {recall_at_3(synonym_expansion[queries_syn[2]], \n",
    "                                        cosine_similarity(queries_syn[2], lemma_tokenized_documents),k=3)}\")\n",
    "print()\n",
    "print(f\"{query_local[2]} RECALL@3: {recall_at_3(local_analysis[query_local[2]], \n",
    "                                        cosine_similarity(query_local[2], lemma_tokenized_documents),k=3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30d1091-2b9c-4735-ae46-2eff56a2d30c",
   "metadata": {},
   "source": [
    "## üß† Reflection Questions\n",
    "\n",
    "<font color='blue'>Please answer the following questions in markdown cells following each question:</font>\n",
    "\n",
    "### Q1: How did normalization affect retrieval performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3ba54f-2e66-4b4d-a610-3b39d68d9894",
   "metadata": {},
   "source": [
    "Normalization affects retreival performance heavily. Firstly, we lowercased which merged many words together in our token list (for example \"Badminton\" and \"badminton\" weren't seperate tokens after lowercasing, which helps lower our index size. Secondly, there were many useless tokens in our tokenized lists which were punctuations such as \".\" and \",\". Removing these are good since they do not help in document retrieval so keeping them in our tokens list is redundant, removing them lowers our space and improves retrieval performance. Also we handled unicode which is useful in retrieval performance, because if it is not handled properly we may miss relevant documents when using retrieval algorithms. We prefer to keep a universal representation of our characters so our retrival can be consistent. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd1e0ec-d67a-49f3-9762-1c0c21a221ab",
   "metadata": {},
   "source": [
    "### Q2: What are the trade-offs between stemming and lemmatization?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6dd30fe-d892-4110-b077-0c920e4a6bb2",
   "metadata": {},
   "source": [
    "While stemming and lemmtizing our documents. It was noticeable that stemming is more imprecise than lemmatization. For example, some words such as \"doubles\" were stemmed to be \"doubl\" which is not a correct word. A lot of words such as double which ended with \"e\" actually got the \"e\" cut off in stemming, which is not ideal. It was also noticeable that the lemmatization algorithm is more accurate, but the trade-off was that it was slower when ran. This makes sense because it has POS awareness. Since our corpus was small, it was not a big issue, but may be a bigg issue when a large corpus for search retreival is used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6eca39-dfc6-4d42-884f-88d56f6666b2",
   "metadata": {},
   "source": [
    "### Q3: How did relevance feedback improve recall?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca17eb68-a5d3-4f9b-bf01-fbe36f085ff5",
   "metadata": {},
   "source": [
    "Normally, the recall should improve after relevance feedback. But due to the small corpus set, adding additional terms in the query may not change anything due to the fact that the queries were probably already pretty accurate when calculating the cosine similarity due to the small sample size. Nowrmally however, the recall and precision using relevance feedback should increase (improve)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79dcf68d-5d7c-4a23-be36-74eb73c3875f",
   "metadata": {},
   "source": [
    "### Q4: Which expansion technique yielded the best precision?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de16dbc-5028-4179-9996-51cc7cd75184",
   "metadata": {},
   "source": [
    "For our scenario and documents, local analysis gave the best results. We can see on query 2 that both precision and recall increased, and did better than our base query and our synonym expansion. This is most likely due to the fact that for synonym expansion, our query and documents aren't very large so not many synonyms of existing words in the document can be found. Local analysis works well in this case since we already assume that the top-k are relevant and gets higher weighted terms from those documents. Overall, both expansion techniques are solid but in this case, local analysis is better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e98b28-de0d-4154-877a-141d28c9a204",
   "metadata": {},
   "source": [
    "## üßÆ Evaluation Criteria\n",
    "\n",
    "| Component                    | Points |\n",
    "|-----------------------------|--------|\n",
    "| Preprocessing implementation | 20     |\n",
    "| Inverted index construction  | 15     |\n",
    "| Evaluation metrics           | 20     |\n",
    "| Relevance feedback & QE      | 25     |\n",
    "| Reflection answers           | 20     |\n",
    "| **Total**                    | **100** |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
