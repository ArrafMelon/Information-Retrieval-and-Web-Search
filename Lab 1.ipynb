{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec7ba65c-42e8-4467-a46a-abc7529b8a51",
   "metadata": {},
   "source": [
    "# <font color='blue'>Lab 1: Information Retrieval Models</font>\n",
    "\n",
    "### Course: Introduction to Information Retrieval\n",
    "### Topics: Boolean Model, Vector Space Model, Probabilistic Model (BM25)\n",
    "\n",
    "### <font color='red'>Submission: Submit both .ipynb file and .ipynb converted to PDF</font>\n",
    "### <font color='blue'>Submissions with following cases will get a zero</font>\n",
    "* ### <font color='blue'>Any compilation error in the notebook</font>\n",
    "* ### <font color='blue'>Missing output for any of the programming cells. There shoould be an output for every code cell</font>\n",
    "  \n",
    "\n",
    "# ============================\n",
    "# üîç Part A: Theoretical Questions (35 Marks)\n",
    "# ============================\n",
    "\n",
    "## Q1: Define the Bag of Words model and explain its role in vector space representation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c427dc-483d-4242-8c75-7321b7a346f4",
   "metadata": {},
   "source": [
    "Theoretical no code/program needed\n",
    "\n",
    "Answer: The bag of words model represents documents as a collection of words. This stores the words as well as the frequency of the words from the document. Bag of words model is also unordered.\n",
    "\n",
    "Example: a document containing the sentence \"I love this this course\", bag of words would be represented by {\"love\":1,\"I\":1,\"this\":2,\"course\":1}\n",
    "\n",
    "It's role in vector space representation is that we can use the words and frequencies and store them in vectors, making them useful in mathematical calculations as normalization of a document, or applying algorithms to rank multiple documents.\n",
    "\n",
    "Example:\n",
    "\n",
    "Document: \"I love this this course\"\n",
    "\n",
    "Vocabulary: [\"I\", \"course\", \"this\", \"love\"]\n",
    "\n",
    "Document: [1,1,2,1]\n",
    "\n",
    "One limitation is that it cannot differentiate between positive/ negative connotations in phrases such as \"not good\" since Bag of words is unordered. The unordering factor also ignores grammar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3387d0-6362-4aaf-bce0-d9fe1754b335",
   "metadata": {},
   "source": [
    "## Q2: Explain each component of TF-IDF formula.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c8588e-0b11-4321-8bc1-a14010ddb52c",
   "metadata": {},
   "source": [
    "Theoretical no code/program needed\n",
    "\n",
    "Answer:\n",
    "\n",
    "So, we know that TF-IDF(t,d) = TF(t,d) x IDF(t) = (Number of times term t appears in document d) x log(N / DF(t))\n",
    "\n",
    "For the TF(t,d) portion, it is simply calculating the number of terms t in a specific document, this means if we have a corpus of documents, we can find a TF score for each document for a specific term\n",
    "\n",
    "for the IDF(t) portion, it helps us understand how rare a term is across our corpus. This is because we divide the total number of documents by only the documents that contain term t. the log is more of a term to smooth the scaling, so rare terms may not be overweighting.\n",
    "\n",
    "Now, when we multiple TF and IDF, the score we get tells us how important the term is in a specific document relative to the entire corpus. A high TF-IDF score tells us that the term appears more in the document relative to the corpus, and opposite happens when the TF-IDF score is low."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171dd6c7-aee4-4572-be4b-9ac35e712fc0",
   "metadata": {},
   "source": [
    "## Q3: What is cosine similarity? Why is it preferred over Euclidean distance in IR?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2339c8-34b2-4c25-8080-99c1a5ada0b9",
   "metadata": {},
   "source": [
    "Theoretical no code/program needed\n",
    "\n",
    "Cosine similarity is used to measure the angle between two vectors, defined by:\n",
    "\n",
    "$Cosine(\\theta)$ = $\\frac{(q \\cdot d)}{\\lVert \\mathbf{q} \\rVert \\lVert \\mathbf{d} \\rVert}$\n",
    "\n",
    "Where q represents the query vector and d represents the document vector\n",
    "\n",
    "The numerator (dot product) shows how \"aligned\" the two vectors are. The denominator removes the factor of vector magnitude. This is crucial because a query and document vectors will in most cases be very different magnitudes, meaning that the length of one vector will affect the similarity score, which we do not want, hence why we include the denominator.\n",
    "\n",
    "The point mentioned above is why cosine similarity is preferred over euclidean distance since euclidean distance factors in the magnitude of vectors. We may have a document that is similar to a query but large in magnitude (docA), and another which is not as similar, but smaller in magnitude (docB). Euclidean distance would tell us that docA is \"farther\" from the query than docB, which would not be correct."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a211565-df63-45a8-a490-6469e8fe3d6e",
   "metadata": {},
   "source": [
    "## Q4: Discuss the impact of document length normalization on term weighting and ranking.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf8fc9d-58a4-4153-9c27-370041aecdf1",
   "metadata": {},
   "source": [
    "Theoretical no code/program needed\n",
    "\n",
    "Document length normalization is needed when term weighting or ranking due to the varying size of documents. A document that is very long may have large frequencies of terms, but may not be a relevant document. When ranking documents, we would like to favour documents that have a higher ratio of term t compared to the document, rather than just the number of occurences of t.\n",
    "\n",
    "We can normalize the frequency of terms in a document by dividing the term frequency of term t in document d by the length of d, this will normalize the frequencies to the range 0-1, giving an even comparison when weighting terms and ranking, rather than being biased towards large documents. Term density is rewarded in this scenario rather than term occurrence in a document.\n",
    "\n",
    "In BM25, we normalize by dividing the length of document d by the average length of a document in the corpus (also we have b as a parameter).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d436bf06-16a2-4a63-8be1-5f7e19ee1f3c",
   "metadata": {},
   "source": [
    "## Q5: What is the Probability Ranking Principle? How does it guide document ranking?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244a8f99-de17-41e8-b0ba-42d4eafffd1a",
   "metadata": {},
   "source": [
    "Theoretical no code/program needed\n",
    "\n",
    "The probability ranking principle works by ranking documents based on the terms it contains that are also in the query, using logarithmic probability. The base algorithm calculates the score of a document based on how relevant it is. The score is found by:\n",
    "\n",
    "1. for each term t in our query q, we divide the probability that t appears in relevant documents r, by the probability of t in non-relevant documents ¬¨r.\n",
    "2. We find the logarithm score of the division\n",
    "3. we sum the logarithmic score over all the terms in q to find our final score.\n",
    "\n",
    "This way, because we find the probability of relevant vs non relevant documents, we can say that the higher the score, the higher estimated probability it has of being relevant to the users query.\n",
    "\n",
    "We must note that this principle on its own ignores the frequency of a term appearing in a document, it only notices if it appears or not. Another limitation is the fact that it does not take into account document length. So a longer document may be favoured over a short document with a higher rate of occurence of a term.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a95934-a664-4610-b746-33cc079811c7",
   "metadata": {},
   "source": [
    "## Q6: Explain the intuition behind BM25 and how it improves over TF-IDF.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39a8b01-423d-4f4a-a900-f8798994f9ad",
   "metadata": {},
   "source": [
    "Theoretical no code/program needed\n",
    "\n",
    "The BM25 is a probabilistic model used as a ranking function using probability to determine relevant documents given a specific query. The problem with TF-IDF is that is assumes that if a term is more frequently mentioned in a document, it is more important linearly. Another limitation is very long documents also contain multiple instances of a specific term, but that's just due to how long the document is, not because it is actually a relevant document. \n",
    "\n",
    "BM25 fixes these issues. Firstly, the problem with higher term frequency leading to higher relevance is addressed by a smoothing function (with parameter k1), which allows higher scores for higher frequencies, but quickly levels out. This is because extra occurrences may not add as much information after a certain point. \n",
    "\n",
    "BM25 also introduces document length normalization (found by dividing length of document d by the average length of a document). This allows for understanding that overly long documents may not be relevant, and it notices concise documents which are more related to our given query)\n",
    "\n",
    "$BM25 = \\sum_{t \\in q} IDF(t) \\times TFSaturation \\times LengthNorm$\n",
    "\n",
    "is the general formula of BM25, as we can see, it introduces the saturation or \"smoothing\" term for TF, and the normalization of documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b840fdea-cdbe-49b5-946e-d443524d5344",
   "metadata": {},
   "source": [
    "## Q7: List two advantages and two limitations of probabilistic models in IR."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ca5725-f5ce-4249-acdf-1b80c88462ee",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "Theoretical no code/program needed\n",
    "\n",
    "Advantages:\n",
    "1. Probabilistic models adapts to feedback. It can use user input to improve its ranking and update its probabilities on relevant/ non-relevant documents.\n",
    "2. The probabilistic model can incorporate frequency and document length to make its decisions. Other models may be naive in thinking that only term frequency itself matters, not accounting for the density of terms per document on relevance. Probabilistic models can fix that issue by introducing normalization and smoothing factors to account for overly long documents with terms appearing a lot of times.\n",
    "\n",
    "Disadvantages:\n",
    "1. Probabilistic models such as BM25 require parameter tuning (for k and b). This may take some time to determine which combination of parameters work best when given the scenario.\n",
    "2. The initial results of a probabilistic model may not be accurate. This is because it has no previous knowledge on relevance. With user feedback, over time the model improves but it is not great in the beginning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30d1091-2b9c-4735-ae46-2eff56a2d30c",
   "metadata": {},
   "source": [
    "# ============================\n",
    "# üíª Part B: Python Implementation Tasks\n",
    "# ============================\n",
    "# 65  Marks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c07a19-bd84-46d5-8a8a-a391b2c573ec",
   "metadata": {},
   "source": [
    "## Q8 (10 marks) Write a Python function that takes a list of documents (each document is a string) and returns an inverted index. The inverted index should be a dictionary where each term maps to a list of document IDs in which the term appears.\n",
    "\n",
    "üìò Example Input\n",
    "documents = [\"the cat sat on the mat\",  \"the dog sat on the log\",  \"the cat chased the dog\"]\n",
    "\n",
    "‚úÖ Expected Output\n",
    "{\n",
    "    'the': [0, 1, 2],\n",
    "    'cat': [0, 2],\n",
    "    'sat': [0, 1],\n",
    "    'on': [0, 1],\n",
    "    'mat': [0],\n",
    "    'dog': [1, 2],\n",
    "    'log': [1],\n",
    "    'chased': [2]\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bb7ad93-7786-4b0f-9c47-6ef1e68fad03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_inverted_index(documents):\n",
    "    \"\"\"\n",
    "    Build an inverted index from a list of documents.\n",
    "\n",
    "    Parameters:\n",
    "    - documents (list of str): A list of raw text documents\n",
    "\n",
    "    Returns:\n",
    "    - dict: Inverted index {term: [doc_ids]}\n",
    "    \"\"\"\n",
    "    output_dict = {}\n",
    "    # Iterate over each document\n",
    "    for idx, doc in enumerate(documents):\n",
    "        # get list of words per document\n",
    "        list_of_words = doc.split()\n",
    "        # Iterate over words, and add index into dictionary value list \n",
    "        for word in set(list_of_words):\n",
    "            word = word.lower()\n",
    "            if word not in output_dict:\n",
    "                output_dict[word] = []\n",
    "            output_dict[word].append(idx)\n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a98ebcf-7541-49e6-8d13-86864bf3f86e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mat': [0], 'on': [0, 1], 'cat': [0, 2], 'sat': [0, 1], 'the': [0, 1, 2], 'log': [1], 'dog': [1, 2], 'chased': [2]}\n"
     ]
    }
   ],
   "source": [
    "documents = [\"the cat sat on the mat\", \"the dog sat on the log\", \"the cat chased the dog\"]\n",
    "res = build_inverted_index(documents)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4f136e-45d5-4c38-9bc4-f0aa2605aa8e",
   "metadata": {},
   "source": [
    "## Q9 (10 marks) Write a Python function that takes inverted index of documents as input and a query string, and returns the list of document IDs that satisfy the query. The query can use the operators AND, OR, and NOT between terms.\n",
    "\n",
    "### üìò Sample Inverted Index\n",
    "index = {'the': [0, 1, 2], 'cat': [0, 2], 'sat': [0, 1], 'on': [0, 1], 'mat': [0], 'dog': [1, 2], 'log': [1], 'chased': [2]}\n",
    "________________________________________\n",
    "### üîç Example Queries and Expected Outputs\n",
    "üîπ Query 1: \"cat AND dog\"\n",
    "#### Documents containing both 'cat' and 'dog'\n",
    "#### cat ‚Üí [0, 2], dog ‚Üí [1, 2]\n",
    "#### Intersection ‚Üí [2]\n",
    "Expected Output: [2]\n",
    "\n",
    "üîπ Query 2: \"cat OR dog\"\n",
    "#### Union of documents with 'cat' or 'dog'\n",
    "#### cat ‚Üí [0, 2], dog ‚Üí [1, 2]\n",
    "#### Union ‚Üí [0, 1, 2]\n",
    "Expected Output: [0, 1, 2]\n",
    "\n",
    "üîπ Query 3: \"cat AND NOT dog\"\n",
    "#### cat ‚Üí [0, 2], dog ‚Üí [1, 2]\n",
    "#### NOT dog ‚Üí all docs except [1, 2] ‚Üí [0]\n",
    "#### Intersection ‚Üí [0]\n",
    "Expected Output: [0]\n",
    "\n",
    "üîπ Query 4: \"sat OR chased\"\n",
    "#### sat ‚Üí [0, 1], chased ‚Üí [2]\n",
    "#### Union ‚Üí [0, 1, 2]\n",
    "Expected Output: [0, 1, 2]\n",
    "\n",
    "üîπ Query 5: \"mat AND NOT sat\"\n",
    "#### mat ‚Üí [0], sat ‚Üí [0, 1]\n",
    "#### NOT sat ‚Üí [2]\n",
    "#### Intersection ‚Üí mat ‚à© NOT sat ‚Üí []\n",
    "Expected Output: []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59aa2e69-6451-4f7f-80ff-45c9e7f78d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_inverted_index(index, query):\n",
    "    \"\"\"\n",
    "    Evaluate a Boolean query using an inverted index.\n",
    "\n",
    "    Parameters:\n",
    "    - index (dict): Inverted index {term: [doc_ids]}\n",
    "    - query (str): Boolean query using 'AND', 'OR', 'NOT'\n",
    "\n",
    "    Returns:\n",
    "    - list of int: Sorted list of document IDs that satisfy the query\n",
    "    \"\"\"\n",
    "    # Split query into list of words\n",
    "    tokens = query.lower().split()\n",
    "    every_word = set(word for doc in index.values() for word in doc)\n",
    "\n",
    "    # Retrieve indices of terms mentioned\n",
    "    index_list = [] \n",
    "    for t in tokens: \n",
    "        if t not in (\"and\",\"or\",\"not\"):\n",
    "            index_list.append(index.get(t, []))\n",
    "\n",
    "    # Logic output\n",
    "    output = []\n",
    "    if \"and\" in tokens:\n",
    "        if \"not\" in tokens:\n",
    "            output = list(set(index_list[0]) & (every_word - set(index_list[1])))\n",
    "        else:\n",
    "            output = list(set(index_list[0]) & (set(index_list[1])))\n",
    "\n",
    "    elif \"or\" in tokens:\n",
    "        if \"not\" in tokens:\n",
    "            output = list(set(index_list[0]) | (every_word - set(index_list[1])))\n",
    "        else:\n",
    "            output = list(set(index_list[0]) | (set(index_list[1])))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27ad645e-7aa8-4710-8756-ed2cffed6ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n",
      "[0, 1, 2]\n",
      "[0]\n",
      "[0, 1, 2]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Show results for all provided test cases\n",
    "index = {'the': [0, 1, 2], 'cat': [0, 2], 'sat': [0, 1], 'on': [0, 1], 'mat': [0], 'dog': [1, 2], 'log': [1], 'chased': [2]}\n",
    "print(query_inverted_index(index,\"cat AND dog\"))\n",
    "print(query_inverted_index(index,\"cat OR dog\"))\n",
    "print(query_inverted_index(index,\"cat AND NOT dog\"))\n",
    "print(query_inverted_index(index,\"sat OR chased\"))\n",
    "print(query_inverted_index(index,\"mat AND NOT sat\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf822cd-8016-46a4-8081-7623115a5d05",
   "metadata": {},
   "source": [
    "# Vector Space Model (20 marks)\n",
    "## Q10.\t(20 marks) Implement a TF-IDF vectorizer from scratch for a small corpus of 3 documents (corpus) and 1 query. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81d5738d-ac39-4974-8142-9363f5345f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def compute_tf_idf(corpus, query):\n",
    "\t\n",
    "    # Prepare TF-IDF vectors for each document and the query following the document TF-IDF document posted on D2L. Return cosine similarity scores\n",
    "\t  # Print all TF-IDF vectors\n",
    "\n",
    "    # Part 1: Find Term frequency for each document and term, including corpus\n",
    "    freq_dict  = {}\n",
    "    for idx, doc in enumerate(corpus):\n",
    "        list_words = doc.split()\n",
    "        for word in list_words:\n",
    "            if word not in freq_dict:\n",
    "                freq_dict[word] = [0] * len(corpus)\n",
    "            freq_dict[word][idx] += 1\n",
    "\n",
    "    # Part 2: IDF\n",
    "    N = len(corpus)\n",
    "    idf_vector = []\n",
    "    for word in freq_dict.keys():\n",
    "        DF_term = sum(1 for num in freq_dict[word] if num != 0)\n",
    "        idf = round(math.log(N / DF_term),3)\n",
    "        idf_vector.append(idf)\n",
    "\n",
    "    # Part 3: TF-IDF\n",
    "    tf_idf_vec = []\n",
    "    for idx, nun in enumerate(corpus):\n",
    "        doc_vec = []\n",
    "        idf_idx = 0\n",
    "        for word in freq_dict.keys():\n",
    "            tf_idf = freq_dict[word][idx] * idf_vector[idf_idx]\n",
    "            doc_vec.append(tf_idf)\n",
    "            # This increments the index of the idf vector so we don't keep multiplying by 1 value only\n",
    "            idf_idx += 1\n",
    "        tf_idf_vec.append(doc_vec)\n",
    "\n",
    "    # Part 4: print all TF-IDF vectors:\n",
    "    print(\"Words\", freq_dict.keys())\n",
    "    for idx,vec in enumerate(tf_idf_vec):\n",
    "        print(\"Document\", idx+1, \"TF-IDF\", tf_idf_vec[idx])\n",
    "\n",
    "    # Part 5: Cosine Similarity\n",
    "    # 5a: prepare document and query vectors, get rid of stopwords\n",
    "    vocabulary = freq_dict.keys()\n",
    "    stopwords = [\"the\",\"on\"]\n",
    "    vocabulary = [w for w in vocabulary if w not in stopwords]\n",
    "\n",
    "    document_vectors = []\n",
    "    for doc in corpus:\n",
    "        words = doc.split()\n",
    "        vector = [words.count(term) for term in vocabulary]\n",
    "        document_vectors.append(vector)\n",
    "\n",
    "    query_vector = [query.split().count(term) for term in vocabulary]\n",
    "    \n",
    "    # 5b: calculate similarity between query and each document\n",
    "    cosine_similarities = []\n",
    "    for idx,doc_vec in enumerate(document_vectors):\n",
    "        dot_prod = sum(x*y for x,y in zip(doc_vec, query_vector))\n",
    "        doc_norm = math.sqrt(sum(x*x for x in doc_vec))\n",
    "        query_norm = math.sqrt(sum(x*x for x in query_vector))\n",
    "        cs = round(dot_prod / (doc_norm*query_norm),3)\n",
    "        cosine_similarities.append((f\"Document {idx+1} Cosine Similarity\",cs))\n",
    "\n",
    "    cosine_similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    return cosine_similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e275552-f7be-40d8-8045-23cc96909b73",
   "metadata": {},
   "source": [
    "## Q11.\t(5 marks) Compute cosine similarity between the query and each document (at least three). Show the ranked results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e95a7f57-88f4-4d1d-94a0-03027580bd1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words dict_keys(['the', 'cat', 'sat', 'on', 'mat', 'dog', 'log', 'chased'])\n",
      "Document 1 TF-IDF [0.0, 0.405, 0.405, 0.405, 1.099, 0.0, 0.0, 0.0]\n",
      "Document 2 TF-IDF [0.0, 0.0, 0.405, 0.405, 0.0, 0.405, 1.099, 0.0]\n",
      "Document 3 TF-IDF [0.0, 0.405, 0.0, 0.0, 0.0, 0.405, 0.0, 1.099]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Document 3 Cosine Similarity', 0.816),\n",
       " ('Document 1 Cosine Similarity', 0.408),\n",
       " ('Document 2 Cosine Similarity', 0.408)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [\"the cat sat on the mat\", \"the dog sat on the log\", \"the cat chased the dog\"]\n",
    "compute_tf_idf(corpus,'cat dog')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d352b28-6827-472f-836b-497bb382de37",
   "metadata": {},
   "source": [
    "# Probabilistic Model ‚Äì BM25 \n",
    "## Q12.\t(15 marks) Implement a simplified BM25 scoring function for a small corpus. Using the formula in slides: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e455bc1-87d1-4a33-b20c-b386b8bd0c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bm25_score(query, corpus, k=1.5, b=0.75):\n",
    "    # Returns BM25 scores for each document\n",
    "    # Part 1: initialize constants (average length of documents)\n",
    "    N = len(corpus)\n",
    "    doc_split = [doc.split() for doc in corpus]\n",
    "    avg_doc_len = sum(len(doc) for doc in doc_split) / N\n",
    "\n",
    "    # Part 2: Find frequency for terms in corpus\n",
    "    freq_dict = {}\n",
    "    for idx,docs in enumerate(doc_split):\n",
    "        for word in docs:\n",
    "            if word not in freq_dict:\n",
    "                freq_dict[word] = [0] * len(corpus)\n",
    "            freq_dict[word][idx] += 1\n",
    "\n",
    "    # Part 3: Find bm25 scores\n",
    "    bm25_scores = []\n",
    "    query_words = query.split()\n",
    "\n",
    "    for idx, doc in enumerate(doc_split):\n",
    "        score = 0\n",
    "        len_doc = len(doc)\n",
    "\n",
    "        # we only calculate terms that are an element of query q\n",
    "        for q_term in query_words:\n",
    "            if q_term in freq_dict:\n",
    "                # Find IDF\n",
    "                DF_term = sum(1 for num in freq_dict[q_term] if num != 0)\n",
    "                idf = math.log(N / DF_term)\n",
    "                # Number of occurences of term in document\n",
    "                f = freq_dict[q_term][idx]\n",
    "                # bm25 score\n",
    "                score += idf*((f*(k+1))/(f+k*(1-b+b*(len_doc/avg_doc_len))))\n",
    "        bm25_scores.append((f\"Document {idx+1} BM25 Score\",round(score,4)))\n",
    "\n",
    "    bm25_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    return bm25_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa666c6-b5f2-43d8-bfd7-df695b20f156",
   "metadata": {},
   "source": [
    "\n",
    "## Q13.\t(5 marks) Compare BM25 scores with TF-IDF scores for the same query and corpus. Discuss the differences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7277861b-1b01-4c74-9f71-7c412075ca7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Document 3 BM25 Score', 0.8563),\n",
       " ('Document 1 BM25 Score', 0.395),\n",
       " ('Document 2 BM25 Score', 0.395)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm25_score(\"cat dog\", corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20ad920-c193-4244-9d13-39d06422eebd",
   "metadata": {},
   "source": [
    "We notice that the rankings of BM25 and TF-IDF seem to rank quite similarly. BM25 algorithm accounts for document length, so it will perform really well compared to TF-IDF when given varying sizes of documents, with different ratios of terms appearing. TF-IDF did not have any normalization factors, although Cosine similarity did."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
